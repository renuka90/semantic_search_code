{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from nltk import SnowballStemmer\n",
    "from gensim.models import Word2Vec\n",
    "#import langdetect\n",
    "import tika\n",
    "import time\n",
    "from tika import parser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Articles pdf Data\n",
    "Convert pdf to text using Tika apache server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the target data folder\n",
    "target_dir = 'C:/Thesis/Data/Academy_of_Management_journal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep pdf extraction\n",
    "pdf_files = []\n",
    "wrd_files = []\n",
    "\n",
    "for f in os.listdir(target_dir):\n",
    "    if f.endswith(\".pdf\") | f.endswith(\".PDF\"):\n",
    "        thispdf = os.path.join(target_dir, f)\n",
    "        pdf_files = pdf_files + [thispdf]\n",
    "    if f.endswith(\".doc\") | f.endswith(\".docx\") | f.endswith(\".DOC\") | f.endswith(\".DOCX\"):\n",
    "        thiswrd = os.path.join(target_dir, f)\n",
    "        wrd_files = wrd_files + [thiswrd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "port = 4321 # port to use for Tika server (chosen arbitrarily)\n",
    "server_str = 'http://localhost:' + str(port)\n",
    "tika_path  = 'C:\\Software\\ tika-server-1.23.jar'\n",
    "tika_run   = 'java -jar' + tika_path + ' --port ' + str(port)\n",
    "print('Command to start Tika:')\n",
    "print(tika_run)\n",
    "print('---')\n",
    "print('Number of pdf files: ' + str(len(pdf_files)))\n",
    "print('Number of word files: ' + str(len(wrd_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the PDF files, store text in memory\n",
    "tika.TikaClientOnly = True \n",
    "\n",
    "# pdf_metadata = [parser.from_file(t, server_str, xmlContent=False)[\"metadata\"] for t in (pdf_files + wrd_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data metadata\n",
    "pickle.dump(pdf_metadata, open( \"C:/Thesis/Data/save/Academy_of_MJ/metadata/metadata_academy.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdf content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the PDF files, store text in memory\n",
    "tika.TikaClientOnly = True \n",
    "\n",
    "#pdf_text = [parser.from_file(t, server_str, xmlContent=False)[\"content\"] for t in (pdf_files + wrd_files)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step: 1 - Load pdf content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load the text data\n",
    "pdf_text = pickle.load(open(\"C:/Thesis/Data/save/Academy_of_MJ/save_alltextData.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step-2 convert it to lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert each string to lowercase\n",
    "for i in range(len(pdf_text)):\n",
    "    pdf_text[i] = pdf_text[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step-3 remove reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pdf_ref = [re.sub(r\"(?is)\\nreferences\\n.+\", \"\", f) for f in pdf_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step-4 load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load the metadata\n",
    "pdf_metadata = pickle.load(open(\"C:/Thesis/Data/save/Academy_of_MJ/metadata/metadata_academy.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  step-5: Get title, subject and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_title = []\n",
    "pdf_Author = []\n",
    "pdf_subject = []\n",
    "\n",
    "\n",
    "for i in pdf_metadata:\n",
    "    temp =\"\"\n",
    "    auth_temp = \"\"\n",
    "    subj_temp = \"\"\n",
    "    try:\n",
    "        temp = i['title']\n",
    "        auth_temp = i['Author']\n",
    "        subj_temp = i['subject']\n",
    "     \n",
    "        pdf_title.append(temp.lower()) \n",
    "        pdf_Author.append(auth_temp.lower()) \n",
    "        pdf_subject.append(subj_temp.lower())\n",
    "       \n",
    "    except:\n",
    "        #print(\"An exception occurred\" )\n",
    "        pdf_title.append(temp.lower())\n",
    "        pdf_Author.append(auth_temp.lower())\n",
    "        pdf_subject.append(subj_temp.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pdf_Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1= remove title and save it\n",
    "import re\n",
    "pdf_text_title = []\n",
    "\n",
    "for i in pdf_ref: # get data - excluding reference section\n",
    "    line = i\n",
    "    #print(line)\n",
    "    for j in pdf_title:\n",
    "        if j !=\" \":\n",
    "            line = re.sub(j, '', line)\n",
    "    #print(line)\n",
    "    pdf_text_title.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text_title[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save removed title\n",
    "pickle.dump(pdf_text_title, open( \"C:/Thesis/Data/save/Academy_of_MJ/metadata/removed_title/metadata_all.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load the metadata\n",
    "pdf_text_title = pickle.load(open(\"C:/Thesis/Data/save/Academy_of_MJ/metadata/removed_title/metadata_all.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process author\n",
    "import re\n",
    "pdf_auth = []\n",
    "\n",
    "for j in pdf_Author:\n",
    "    k = re.sub(' and ', ',', j)\n",
    "    k = re.sub(' & ', ',', k)\n",
    "    k = k.split(\",\")\n",
    "    pdf_auth.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove author from the content \n",
    "# pdf_text_author = []\n",
    "\n",
    "# for i in pdf_text_title:\n",
    "#     line = i\n",
    "#     # for author\n",
    "#     for j in pdf_auth:\n",
    "#         for k in j:\n",
    "#             line = re.sub(k.strip(), '', line)\n",
    "        \n",
    "#     pdf_text_author.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save removed author\n",
    "pickle.dump(pdf_text_author, open( \"C:/Thesis/Data/save/Academy_of_MJ/metadata/removed_title_author/metadata_all.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required\n",
    "def eliminate_method_result(method, discussion):\n",
    "    \n",
    "    import re    \n",
    "    start = method\n",
    "    end = discussion\n",
    "    #start of pattern, followed by any number of times 'any character OR a newline' and terminated by the end pattern.\n",
    "    pattern = start + '.*'+'(.|\\n)*'+end\n",
    "    pdf_method_dis = [re.sub(pattern, '', f) for f in pdf_text]\n",
    "\n",
    "    return pdf_method_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required\n",
    "def eliminate_method_result_ref(method, dis, ref):\n",
    "    \n",
    "    import re\n",
    "\n",
    "    start = method\n",
    "    end = dis\n",
    "    \n",
    "    #start of pattern, followed by any number of times 'any character OR a newline' and terminated by the end pattern.\n",
    "    pattern = start + '.*'+'(.|\\n)*'+end\n",
    "    pdf_method_dis = [re.sub(pattern, '', f) for f in pdf_text]\n",
    "    \n",
    "    start_ref = ref\n",
    "    pattern_ref = start_ref +'(.|\\n)*$'\n",
    "\n",
    "    pdf_ref= [re.sub(pattern_ref, '', f) for f in pdf_method_dis]\n",
    "    \n",
    "    return pdf_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "Regular expression is used to clean up the pre-processed data and saved as a Master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_p= [re.sub(r\"-\\n(\\n)*\", \"\", t)for t in pdf_text_title]\n",
    "\n",
    "pdf_p= [re.sub(r\"\\n(\\n)*\", \"\\n\", t)for t in pdf_p]\n",
    "\n",
    "pdf_p= [re.sub(r\"\\n\", \" \", t)for t in pdf_p]\n",
    "# remove text with [] eg citation\n",
    "pdf_p = [re.sub(r\"\\[[^)]*\\]\", \"\", t)for t in pdf_p]\n",
    "#Remove numbers\n",
    "pdf_p = [re.sub('[0-9]+', '', f) for f in pdf_p]\n",
    "#pdf_p = [re.sub(\"r[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?\", \" \", t)for t in pdf_p]\n",
    "pdf_p = [re.sub('[!@/%“”‘:#©β<>+=δχ*&$]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’s','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’re','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’t','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’ve','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’ll','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’m','', f) for f in pdf_p]\n",
    "\n",
    "pdf_p = [re.sub('[:()-]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('[\\.!?]+ ', 'XYZXYZ', t) for t in pdf_p]\n",
    "# \\w will match alphanumeric characters and underscores\n",
    "# [^\\w] will match anything that's not alphanumeric or underscore\n",
    "pdf_p = [re.sub(r'[^\\w]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('XYZXYZ', '.', f) for f in pdf_p]\n",
    "pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "# Replace multiple dots with one dot\n",
    "pdf_p = [re.sub('\\.\\.+',\".\", f) for f in pdf_p]\n",
    "pdf_p = [re.sub(r'\\b\\w{1,3}\\b',\"\", f) for f in pdf_p]\n",
    "pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "\n",
    "pdf_p = [re.sub(\"^\\s+\",\"\", f) for f in pdf_p]# remove the front space\n",
    "pdf_p = [re.sub(\"\\s+\\Z\",\"\", f) for f in pdf_p]#remove the back space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'developing field with more soul standpoint theory public policy research management scholars paul adler university southern california john jermier university south florida believe that question whether should more involved scholarship research that relevant public policy paramount importance development academy management each scholars management. live world immense unnecessary suffering destruction.immense this needs explanation this season news reports suffice.unnecessary much human suffering environmental destruction inevitable result earthly existence rather humanity making.they result wanton exploitation therefore remediable.facing this human made misery posture quiet acceptance would mean tacit endorsement. view this position cannot defended ethically. ethical imperative even greater people like whose comfort part these processes exploitation. must chose action over inaction then what type involvement would right side issues would help contribute solving such problems. stakes associated with these questions highlighted editors this academy management journal forum involve esteem funding profession members.more importantly questions also raise provocative ethical issues about nature profession about research each undertakes.attempting answer these questions brings face face with some thorniest issues contemporary philosophy science with some severe limitations management research currently practiced. code ethical conduct research management organization against this backdrop exploitation suffering destruction that find inspiration code ethical conduct which includes statement members academy play vital role encouraging broader horizon decision making viewing issues from multiplicity perspectives including perspectives those least advantaged. successful community scholars educators articulating perspectives least advantaged understood exploited people natural environments.this enormous question that raise here provoke thinking more than provide complete answer. start with some data. recent study walsh weber margolis coded every empirical article published predecessor journal academy management years .using expansive definition they classified each dependent variable welfare addressed facet health satisfaction justice social responsibility environmental stewardship.they classified dependent variable performance addressed technical accounting financial performance level aggregation.over this period some percent articles addressed welfare performance percent addressed performance welfare percent addressed both percent addressed neither. trend even more telling since proportion articles that have addressed welfare kind level aggregation with without addressing performance declined almost continuously from high around percent average around percent last five years walsh colleagues period study. proportion that addressed performance grown continuously.these data definitive lend credence walsh .conclusion that research focused little progressively less social welfare objectives enterprise. extent that this pattern valid estimate tendencies field flagship journals raises questions about values politics that generate this research priorities about interests that served this emphasis. academy management journal . . . study similar type focused natural environment jermier forbes benn orsato found rapid increases absolute numbers scholarly articles published environment related topics over period .however even most recent period articles environmental topics constituted only tiny proportion total published about percent.this same tiny ratio also characterized rated management organizational studies journals years . ratings journals were based citation impact quotient social science citation index year . this means that every study environment related topic management organizations literature there others that significantly address environmental issues. light rapid continual deterioration health ecosystems this pattern again raises questions about field research priorities interests being served this emphasis. pattern that reflected these studies accurately gauges tendencies management organizational research literature difficult advancing perspectives least advantaged.without strong articulation these perspectives limited ability contribute positively public policy which surely depends fuller knowledge about social environmental problems. better.alternative standpoints conscious engagement with public policy issues main point commentary that entanglement with public policy issues inevitable field this entanglement often unrecognized.bill ouchi recent work devoted remedying problems public education united states good example management research consciously explicitly speak pressing issues public concern.however management research inevitably implies political values therefore implications public policy. realize that this point view will seem misguided some readers.many management scholars believe that forms partisanship should purged from scientific research theory development.they contend that politics should enter into processes knowledge creation many hold that inappropriate scholars engage actively application knowledge.they believe that value neutral objectivity hallmark proper scientific work that advocacy would undermine that objectivity. urge colleagues consider another view that more skeptical goal value neutrality that advocates reflexive inquiry about values underwriting work. world with much unnecessary suffering destruction agger critique value neutrality rings loudly seeming avoidance values strongest value commitment .various writers philosophy science have addressed question values best developed approaches standpoint theory anderson overview comparison with other epistemologies .standpoint theory challenges aspirations value neutrality with argument that these aspirations require scientists trick adopt view from nowhere harding .that they require scholars speak authoritatively without bias from particular human position social location.standpoint theorists contend that this impossible.they argue that objectivity understanding better served aware make explicit epistemological political baggage rather than deny carry .kinchloe mclaren .because there facts without theories because theories based standpoint that shaped least part political considerations scholars should reflect their underlying epistemological assumptions develop awareness their standpoints. also follows that should consciously choose standpoints take responsibility impact lack impact scholarship world.standpoint theory advocates challenge conventional research philosophy arguing that research going help alleviate rather than ignore exacerbate human made suffering destruction around concern this suffering destruction should guide entire research process.according standpoint theory phases research study identifying issues theorizing research questions gathering analyzing data drawing conclusions using knowledge produced conditioned some extent researcher standpoint jermier .deeper more objective knowledge results from attempting eliminate politics from science from embracing politics reflexively consciously adopting appropriate standpoint. what standpoint should adopt. adopt dominant elite standpoints inevitably encourages legitimization naturalization status creating unacceptable limits what learned what change possible. standpoint theory data were from inform proquest database. decemberacademy management journal argument that although standpoints limiting knowledge partial view from below greater potential generate more complete more objective knowledge claims. harding research should begin with concrete circumstances lived experiences systematically oppressed exploited dominated those have fewer interests ignorance about social order actually works .that desire heal world will learn more about root mechanisms world work about things changed adopting standpoints those people other parts nature that most deeply suffer wounds.standpoint theory thus provides guidance where begin inquiry what study. primary recommendation researchers study begin with exploited with intent mapping ways dominant institutions their conceptual frameworks create maintain oppressive social relations harding also wedel shore feldman lathrop . goal should create knowledge that raises consciousness about exploitation helps movement toward emancipation.some readers might think mandate scholars management requires choose standpoint managers.some might argue that researchers place such emphasis social environmental issues simply wrong field.some might assert that primary audience outside academics managers themselves that managers obligated their fiduciary responsibilities consider social environmental issues only they promote short profit maximization. familiar with arguments that society best served when firms maximize profits leave welfare concerns philanthropists government civil society.this line argument neither theoretically practically defensible especially face evidence such approach endangers planet that business performance itself enhanced when managers accountable broader range stakeholders margolis walsh orlitzky schmidt rynes .managers lives made easier greater awareness issues they experienced interpreted exploited managers employees themselves most cases human beings they exploited their solidarity even they simultaneously tugged other directions. management scholars therefore reason much more research might take primary referent exploited groups broader abused natural environment.clearly fields that rely only primarily elite standpoints have blind spots that fields with more pluralistic epistemology able avoid.there therefore good reason encourage more management scholarship that takes alternative standpoints such those lower level employees women poverty racial ethnic sexual minorities disadvantaged communities natural environment. believe that there much learned begin research process formulating questions from these alternative standpoints then examine reality management organizations from these perspectives.this seems entirely consistent with letter spirit code ethical conduct referenced above. this epistemological pluralism were taken seriously could expect witness development field with more soul. could expect find more management research motivated desire understand challenges facing example union organizers wage women workers undocumented immigrant laborers local community activists fighting polluting factory topics central discussions contemporary social environmental policy.thus even specific expertise often equip work directly public policy problems research always public policy implications provide actionable knowledge exploited their advocates. this promote more just more democratic public policy debate. more complicated issue private public policy makers might knowledge that produced from alternative standpoints that underlying emancipatory intent.some advocates exploited might fear appropriation cooptation greater probability that this type knowledge would persuade some elites even owners corporate managers from monolithic their values interests advocate standpoint epistemology because provokes thinking about sometimes hidden otherwise unexamined assumptions that guide scholarly inquiry because makes reasoned case working with alternative assumptions exploited referents. space available this commentary cannot justice complex philosophical issues involved affiliating with exploited harding . here want clear that epistemology refer whole domain research methodology merely whether choose quantitative qualitative data analysis harding adler jermier take enlightened steps direction humane ecocentric policy making. illustration consider program research social scientist gedicks.this research begins from explicit standpoint driven emancipatory intent both scientific activist objectives.gedicks described involvement researcher consultant advocate native sakogon ojibwe people wisconsin their successful struggle against exxon billiton.this struggle involved unusual alliance native american environmental sportfishing interests.gedicks account highlights different which scientists contribute public policy servants elite power resource helping empower other actors amplifying their voices policy debates building supportive action networks. research community faces some challenges when comes steering discipline direction greater positive impact broader range public policy issues.first prevailing philosophy science tends emphasize disengagement with real world politics favor attempts value neutrality nonpartisan objectivity.although this philosophy science still garners respect seems attainable inevitably misleading because research political dimension. research moves direction either reinforcing undermining existing relations power even researchers aware these possible impacts.second where there intentional engagement with real world politics appears more often behalf managers agents owners other elites. standpoints that adopted implicitly explicitly make more likely that knowledge produced will useful relatively privileged rather than helpful generating policy protect less privileged natural environment. code ethical conduct which encourages multiplicity perspectives should serve basis more reflexive inquiry more progressive contributions public policy.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove author from the content --running\n",
    "# pdf_text_author = []\n",
    "\n",
    "# for i in pdf_p:\n",
    "#     line = i\n",
    "#     # for author\n",
    "#     for j in pdf_auth:\n",
    "#         for k in j:\n",
    "#             line = re.sub(k, '', line)\n",
    "        \n",
    "#     pdf_text_author.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\n",
    "stopwords += ['january', 'february', 'march', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "# author name to remove\n",
    "stopwords +=['karina nielsen','kevin daniels','elaine', 'jaewan yang','andrew O herdman','amanda', 'sabine','kerstin','kertin','sagepub','journalspermissions','catheine','chidiebere ogbonnaya','john wiley','sons ltd','martin','jeffrey B arthur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out the stopwords and authors names\n",
    "def filterWords(msg, words):\n",
    "    m = msg.split(' ')\n",
    "    words_end = [w + '.' for w in words]\n",
    "    filtered_words = list(filter(lambda word: word not in words, m))\n",
    "    filtered_words = [(w if w not in words_end else '.') for w in filtered_words]\n",
    "    result = ' '.join(filtered_words)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc = [filterWords(f, stopwords) for f in pdf_p]  #running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "word_tokens = word_tokenize(str(pdf_p) )\n",
    "filtered_sentence = [w for w in word_tokens if not w in stopwords] \n",
    "  \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stopwords: \n",
    "        filtered_sentence.append(w) \n",
    "\n",
    "print(filtered_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_1 = [filterWords(f, str(pdf_auth)) for f in data_proc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "country_list = []\n",
    "for country in pycountry.countries:\n",
    "    a = (country.name).lower()\n",
    "    country_list.append(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_country =[]\n",
    "for j in data_proc:\n",
    "    line = j\n",
    "    for k in country_list:\n",
    "        line = re.sub(k, '', line)\n",
    "        \n",
    "    data_proc_country.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save removed \n",
    "pickle.dump(data_proc_country, open( 'C:/Thesis/Data/save/Academy_of_MJ/metadata/removed_country/metadata_all.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors names are saved already (code is available at author name folder-get name list notebook)\n",
    "#load authors names\n",
    "import pickle\n",
    "author_AMJ = pickle.load(open(\"C:/Thesis/Data/save/Master_Data/auth_ref_filter_num_char/auth_Academy_of_MJ.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_AMJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english') + author_AMJ\n",
    "\n",
    "#print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET RID OF THE STOPWORDS IN TEXTS\n",
    "data_proc_1 = [filterWords(f, sw) for f in data_proc_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "pickle.dump(data_proc_1, open( \"C:/Thesis/Data/save/Master_Data/MD_4/data_proc_latest/AMJ_data_proc.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import io\n",
    "with open(\"C:/Thesis/Data/save/Master_Data/MD_4/data_proc_latest/AMJ_data_proc_txt.txt\", \"w\",encoding=\"utf-8\") as outfile:\n",
    "    for i in range(len(data_proc_1)):\n",
    "        outstring = \"\"\n",
    "        outstring += str(data_proc_1[i])\n",
    "        outfile.write(outstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
