{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from nltk import SnowballStemmer\n",
    "from gensim.models import Word2Vec\n",
    "#import langdetect\n",
    "import tika\n",
    "import time\n",
    "from tika import parser\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Articles pdf Data\n",
    "Convert pdf to text using Tika apache server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the target data folder\n",
    "target_dir = 'C:/Thesis/Data/Journal_of_organizational_behavior'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep pdf extraction\n",
    "pdf_files = []\n",
    "wrd_files = []\n",
    "\n",
    "for f in os.listdir(target_dir):\n",
    "    if f.endswith(\".pdf\") | f.endswith(\".PDF\"):\n",
    "        thispdf = os.path.join(target_dir, f)\n",
    "        pdf_files = pdf_files + [thispdf]\n",
    "    if f.endswith(\".doc\") | f.endswith(\".docx\") | f.endswith(\".DOC\") | f.endswith(\".DOCX\"):\n",
    "        thiswrd = os.path.join(target_dir, f)\n",
    "        wrd_files = wrd_files + [thiswrd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 4321 # port to use for Tika server (chosen arbitrarily)\n",
    "server_str = 'http://localhost:' + str(port)\n",
    "tika_path  = 'C:\\Software\\ tika-server-1.23.jar'\n",
    "tika_run   = 'java -jar' + tika_path + ' --port ' + str(port)\n",
    "print('Command to start Tika:')\n",
    "print(tika_run)\n",
    "print('---')\n",
    "print('Number of pdf files: ' + str(len(pdf_files)))\n",
    "print('Number of word files: ' + str(len(wrd_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the PDF files, store text in memory\n",
    "tika.TikaClientOnly = True \n",
    "\n",
    "pdf_metadata = [parser.from_file(t, server_str, xmlContent=False)[\"metadata\"] for t in (pdf_files + wrd_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data metadata\n",
    "pickle.dump(pdf_metadata, open( \"C:/Thesis/Data/save/Journal_of_organizational_behavior/metadata/metadata_all.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data\n",
    "\n",
    "Eliminate title, sections (eg: content between Method and Discussion) and Reference. It is saved as a pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process the PDF files, store text in memory\n",
    "tika.TikaClientOnly = True \n",
    "\n",
    "#pdf_text = [parser.from_file(t, server_str, xmlContent=False)[\"content\"] for t in (pdf_files + wrd_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step-1 Load pdf content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load the text data\n",
    "pdf_text = pickle.load(open(\"C:/Thesis/Data/save/Journal_of_organizational_behavior/save_alltextData.p\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-2 convert it to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert each string to lowercase\n",
    "for i in range(len(pdf_text)):\n",
    "    pdf_text[i] = pdf_text[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excluding pdfs if it doesnot have the standard format\n",
    "check the standard format of pdf- if it contains method and discussion section or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pdf_included =[]\n",
    "pdf_excluded =[]\n",
    "\n",
    "for i in pdf_text:\n",
    "    flag_1 = re.search(r'\\n(general )?discussion\\n', i)\n",
    "    flag_2 = re.search(r'\\nmethods?\\n', i)\n",
    "   \n",
    "    if flag_1 and flag_2: \n",
    "        pdf_included.append(i)\n",
    "     \n",
    "    else:\n",
    "        pdf_excluded.append(i)\n",
    "len(pdf_included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-3 remove reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove references section \n",
    "import re\n",
    "pdf_ref = [re.sub(r\"(?is)\\nreferences\\n.+\", \"\", f) for f in pdf_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-4 load metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#load the text data\n",
    "pdf_metadata = pickle.load(open(\"C:/Thesis/Data/save/Journal_of_organizational_behavior/metadata/metadata_all.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step-5 get metadata = author, subject, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_title = []\n",
    "pdf_Author = []\n",
    "pdf_subject = []\n",
    "\n",
    "for i in pdf_metadata:\n",
    "    try:\n",
    "        temp = i['title'] # got an error - multiple repeat at position 73\n",
    "        auth_temp = i['Author']\n",
    "        subj_temp = i['subject']\n",
    "      \n",
    "        pdf_title.append(temp.lower()) # \n",
    "        pdf_Author.append(auth_temp) # author will be added in the stopwords list\n",
    "        pdf_subject.append(subj_temp.lower()) # subject is filtered\n",
    "        \n",
    "    except:\n",
    "        #print(\"An exception occurred\" )\n",
    "        pdf_title.append(temp.lower())\n",
    "        pdf_Author.append(auth_temp)\n",
    "        pdf_subject.append(subj_temp.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process author\n",
    "import re\n",
    "pdf_auth = []\n",
    "\n",
    "for j in pdf_Author:\n",
    "    k = re.sub(' and ', '', str(j))\n",
    "    k = re.sub('[!;&$]', '', k)\n",
    "    k = re.sub('[0-9]+', '', k)\n",
    "    k = re.sub( r'\\b\\w{1,3}\\b', '', k)\n",
    "    k = re.sub( r'-', ' ', k)\n",
    "#     pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "    k = re.sub(' +', ',', k)\n",
    "    k = k.split(\",\")\n",
    "   \n",
    "    pdf_auth.append(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got error \n",
    "# pdf_text_title = []\n",
    "\n",
    "# for i in pdf_ref:\n",
    "#     line = i\n",
    "#     # for author\n",
    "#     for j in pdf_title:\n",
    "#         line = re.sub(j, '', line)\n",
    "        \n",
    "#     pdf_text_title.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# step-1 preprocess subject \n",
    "pdf_sub = []\n",
    "\n",
    "  # pre-processing for subject\n",
    "for i in pdf_subject:\n",
    "    # remove special character\n",
    "    t = (re.sub(r'[?\\-|.|:|!]','',i))\n",
    "    # remove digits\n",
    "    t = (re.sub(\"\\d+\", \"\", t))\n",
    "    # remove end whitespace\n",
    "    t = re.sub(r\"\\s+$\",\"\",t)\n",
    "    # append to the list\n",
    "    pdf_sub.append(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text_subject = [] #running\n",
    "\n",
    "for i in pdf_ref:\n",
    "    line = i\n",
    "\n",
    "    for j in pdf_sub:\n",
    "        line = re.sub(j, '', line)\n",
    "        \n",
    "    pdf_text_subject.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text_subject[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required\n",
    "def eliminate_method_result(method, discussion):\n",
    "    \n",
    "    import re    \n",
    "    start = method\n",
    "    end = discussion\n",
    "    #start of pattern, followed by any number of times 'any character OR a newline' and terminated by the end pattern.\n",
    "    pattern = start + '.*'+'(.|\\n)*'+end\n",
    "    pdf_method_dis = [re.sub(pattern, '', f) for f in pdf_text]\n",
    "\n",
    "    return pdf_method_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not required\n",
    "def eliminate_method_result_ref(method, dis, ref):\n",
    "    \n",
    "    import re\n",
    "\n",
    "    start = method\n",
    "    end = dis\n",
    "    \n",
    "    #start of pattern, followed by any number of times 'any character OR a newline' and terminated by the end pattern.\n",
    "    pattern = start + '.*'+'(.|\\n)*'+end\n",
    "    pdf_method_dis = [re.sub(pattern, '', f) for f in pdf_text]\n",
    "    \n",
    "    start_ref = ref\n",
    "    pattern_ref = start_ref +'(.|\\n)*$'\n",
    "\n",
    "    pdf_ref= [re.sub(pattern_ref, '', f) for f in pdf_method_dis]\n",
    "    \n",
    "    return pdf_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pre-processing\n",
    "Regular expression is used to clean up the pre-processed data and saved as a Master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pdf_p= [re.sub(r\"-\\n(\\n)*\", \"\", t)for t in pdf_text_subject]\n",
    "\n",
    "pdf_p= [re.sub(r\"\\n(\\n)*\", \"\\n\", t)for t in pdf_p]\n",
    "\n",
    "pdf_p= [re.sub(r\"\\n\", \" \", t)for t in pdf_p]\n",
    "# remove text with [] eg citation\n",
    "pdf_p = [re.sub(r\"\\[[^)]*\\]\", \"\", t)for t in pdf_p]\n",
    "#Remove numbers\n",
    "pdf_p = [re.sub('[0-9]+', '', f) for f in pdf_p]\n",
    "#pdf_p = [re.sub(\"r[\\S]+\\.(net|com|org|info|edu|gov|uk|de|ca|jp|fr|au|us|ru|ch|it|nel|se|no|es|mil)[\\S]*\\s?\", \" \", t)for t in pdf_p]\n",
    "pdf_p = [re.sub('[!@/%“”‘:#©β<>+=δχ*&$]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’s','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’re','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’t','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’ve','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’ll','', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('’m','', f) for f in pdf_p]\n",
    "\n",
    "pdf_p = [re.sub('[:()-]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('[\\.!?]+ ', 'XYZXYZ', t) for t in pdf_p]\n",
    "# \\w will match alphanumeric characters and underscores\n",
    "# [^\\w] will match anything that's not alphanumeric or underscore\n",
    "pdf_p = [re.sub(r'[^\\w]', ' ', f) for f in pdf_p]\n",
    "pdf_p = [re.sub('XYZXYZ', '.', f) for f in pdf_p]\n",
    "pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "# Replace multiple dots with one dot\n",
    "pdf_p = [re.sub('\\.\\.+',\".\", f) for f in pdf_p]\n",
    "pdf_p = [re.sub(r'\\b\\w{1,3}\\b',\"\", f) for f in pdf_p]\n",
    "pdf_p = [re.sub(' +', ' ', f) for f in pdf_p]\n",
    "\n",
    "pdf_p = [re.sub(\"^\\s+\",\"\", f) for f in pdf_p]# remove the front space\n",
    "pdf_p = [re.sub(\"\\s+\\Z\",\"\", f) for f in pdf_p]#remove the back space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = ['ines', 'meyer','stuart','carr','lori', 'foster', 'joseph','allen','nale', 'lehmann']\n",
    "author_list += ['willenbrock', 'steven', 'rogelberg', 'david', 'antons', 'mathieu', 'declerck', 'kathleen', 'diener', 'iring', 'koch']\n",
    "author_list += ['frank', 'piller', 'kara', 'arnold', 'catherine', 'connelly', 'gellatly', 'megan', 'walsh', 'michael', 'withey']\n",
    "author_list += ['susan', 'ashford', 'wellman', 'mary', 'sully', 'luque', 'katleen',  'stobbeleir', 'melody', 'wollan', 'blake']\n",
    "author_list += ['ashforth', 'glen', 'kreiner', 'mark', 'clark', 'fugate', 'neal','ashkanasy', 'uqbweave', \"neal\", \"ashkanasy\"]\n",
    "author_list += ['william', \"becker\", 'david', \"waldman\", 'oluremi', \"ayoko\", 'karen', \"jehn\", \"soroush\", \"aslani\", 'jimena']\n",
    "author_list += ['ramirez', \"marin\", 'jeanne', \"brett\", 'jingjing', 'zhaleh', 'semnani', \"azad\", \"zhang\", \"tinsley\", 'laurie']\n",
    "author_list += [\"weingart\", 'wendi', \"adair\", 'prasad', 'balkundi','wang','rajiv', 'kishore', \"boris\", \"baltes\", 'kevin']\n",
    "author_list += [\"wynne\", 'mgrdich', \"sirabian\", 'daniel', \"krenn\", 'annet', \"lange\", 'sarah', 'bankins', 'george', 'banks', 'sven']\n",
    "author_list += ['kepes', 'mahendra', 'joshi', 'anson', 'seers', 'larissa','barberchristopher','budnick', 'william','beckerrussell'] \n",
    "author_list += ['cropanzano', 'thomas', 'becker', 'guclu', 'atinc', 'james', 'breaugh', 'carlson', 'jeffrey']\n",
    "author_list += ['edwards', 'paul', 'spector', 'terry','beehr', \"terry\", \"beehr\", 'jennifer', \"ragsdale\", 'jonathan']\n",
    "author_list += [\"kochert\", 'peter', 'belmijeffrey', 'pfeffer', 'andrew', 'bennett', 'bakker', 'field', 'carmen', 'binnewies','sabine']\n",
    "author_list += ['sonnentag', 'mojza', 'michal', 'bironmarc', 'veldhoven', 'douglas','bonettthomas','wright', \"anthony\"] \n",
    "author_list += [\"boyce\", 'levi', \"nieminen\", \"gillespie\", 'marie', \"ryan\", \"denison\", 'kimberley']\n",
    "author_list += ['breevaart', 'evangelia', 'demerouti', 'daantje', 'derks', 'nicola', 'breugst', 'rebecca', 'preller', 'holger']\n",
    "author_list += ['patzelt', 'dean', 'shepherd', 'roman', 'briker','frank', 'walter','michael','cole', 'robert', 'buch','bård', 'kuvaas']\n",
    "author_list += ['anders', 'dysvik', \"claudia\", \"buengeler\", 'astrid', \"homan\", \"voelpel\",'travis']\n",
    "author_list += ['maynard', 'deanna', 'kennedy', 'christian', 'resick', 'anne', 'burmeister', 'yixuan', 'wang', 'junqi', 'yanghua']\n",
    "author_list += ['vantilborgh','joeri', 'hofmans','timothy','judge', 'olivia', 'byza', 'sebastian', 'schuh']\n",
    "author_list += ['stefan', 'dörr', 'matthias', 'spörrle', 'günter', 'maier', 'paul', 'harveymarie', 'dasborough', 'francesco']\n",
    "author_list += ['cangiano', 'sharon', 'parker', 'gillian', 'dawn', 'merideth', 'thompson', 'wayne', 'crawford', 'michele', 'kacmar']\n",
    "author_list += ['abraham', 'carmeli', 'stephen', 'brammer', 'emanuel', 'gomes', 'shlomo', 'tarba', 'mark','martinkojeremy','mackey']\n",
    "author_list += ['filipa', 'castanheira', 'fabrice', 'cavarretta', 'laura', 'trinchera', 'dong', 'choi', 'sean', 'hannah']\n",
    "author_list += ['lucia', 'ceja', 'heesun', 'chae','jisung', 'park','choi', 'melissa', 'chamberlin', 'newton', 'jeffery']\n",
    "author_list += ['lepine','ling', 'chang', \"jennifer\", 'chatman', 'caldwell', 'charles', \"reilly\", 'bernadette', 'doerr']\n",
    "author_list += [\"caldwell\",  \"reilly\", \"doerr\", \"david\", \"charles\", \"bernadette\", \"doerr\", 'tingting', 'chen','kwok']\n",
    "author_list += ['leung','fuli','zhanying','ying', 'chen', 'zhen', 'xiong', 'lifeng', 'zhong', 'jooyeon', 'xiujuan']\n",
    "author_list += ['zhang', 'zhiqiang', 'daniel', 'ming', 'chngjoyce', 'cong', 'ying', 'wang', 'jaee', 'chomichael','morris']\n",
    "author_list += ['jaepil', 'andrea', 'kyongji', 'seongmin', 'jong', 'park', 'bora', 'kwon','chun','kyoungmin','john','sosik','hyeok']\n",
    "author_list += ['chung','choi','jing','peter','colemankatharina','kugler']\n",
    "author_list += ['brizzi', 'catherine', 'matej', 'černe', 'anders', 'dysvik', 'miha', 'škerlavaj', 'samantha','conroynina']\n",
    "author_list += ['gupta', 'samantha', 'conroy', 'christine', 'henle', 'lynn', 'shore', 'samantha', 'stelman', 'neil', 'conway']\n",
    "author_list += ['clinton', 'jane', 'sturges', 'budjanovcanin', 'jose','cortina','cristina', 'costa', 'ashley', 'fulmer']\n",
    "author_list += ['neil', 'anderson','services', 'marcus', 'credépeter','harms', 'jeffrey','cucinamichael','mcdaniel', 'carla', 'gomes'] \n",
    "author_list += ['costa','zhou','aristides','ferreira', 'jason','dahlingmelissa','gutworth', 'marie','dasborough', 'marie']\n",
    "author_list += ['dasboroughpaul', 'harvey', \"emily\", \"david\", 'derek', \"avery\"]\n",
    "author_list += [\"witt\", 'patrick', \"mckay\", 'sarah', 'dawkins', 'tian', 'alexander', 'newman', 'angela', 'martin', 'kevin', 'dawson']\n",
    "author_list += ['kimberly', \"brien\", 'terry', 'beehr','meulenaere','christophe', 'boone','tine', 'buyl', 'frank']\n",
    "author_list += ['daan', 'scheepers', 'naomi', 'ellemers', 'sassenberg', 'annika', 'scholl', 'nathalie', 'delobbe', 'helena', 'cooper']\n",
    "author_list += ['thomas', 'roxane', 'hong', 'deng','frank', 'walter','yanjun', 'guan', 'lindsay', 'dhanani', 'amanda', 'main']\n",
    "author_list += ['andrew', 'pueschel', 'rebekah', 'dibble', 'mihaela', 'dimitrova', 'angela','dionisijulian', 'barling', 'direnzo']\n",
    "author_list += ['marco', 'greenhaus', 'weer', 'christy','stanislav','dobrevjennifer', 'merluzzi', 'yuntao', 'kathryn']\n",
    "author_list += ['bartol', 'chenwei', 'danyang', 'derks', 'chang', 'erin', 'eatough', 'laurenz', 'meier', 'ivana', 'igic', 'achim']\n",
    "author_list += ['elfering', 'spector', 'norbert', 'semmer', 'ludvig', 'levasseur', 'abbie', 'shipp', 'yitzhak', 'fried', 'denise']\n",
    "author_list += ['rousseau', 'philip', 'zimbardo', 'silke', 'astrid', 'eisenbeissdaan', 'knippenberg', \"robert\", \"eisenberger\"]\n",
    "author_list += ['mindy', 'krischer', \"shoss\", 'gökhan', \"karagonlar\", 'gloria', 'gonzalez', \"morales\", 'robert', \"wickham\", 'louis']\n",
    "author_list += [\"buffardi\", 'gabi', 'eissascott','lester', 'liat', 'eldoritzhak', 'harpaz', 'pervez', 'ghauri', 'john', 'child']\n",
    "author_list += ['simon', 'collinson','parker', 'ellen','kyle','emichli','olga', 'epitropaki', 'ilias']\n",
    "author_list += ['kapoutsis', 'ellen', 'gerald', 'ferris', 'konstantinos', 'drivas', 'anastasia', 'ntotsi', 'miriam', 'erez','andrew']\n",
    "author_list += ['cynthia','jinyan', 'fanlei','steven','farmerlinn', 'dyne', 'kayla', 'follmer']\n",
    "author_list += ['isaac', 'emmanuel', 'sabat', 'rose', 'siuta', \"marion\", \"fortin\", 'irina', \"cojuharenco\", \"patient\", 'hayley']\n",
    "author_list += [\"german\", 'katherine', 'frear', 'paustian', 'underdahl', 'eric', 'heggestad', 'lisa', 'slattery', 'walker','ashley']\n",
    "author_list += ['fulmercheri', 'ostroff', 'marylène', 'gagné', 'khee', 'seng', 'benjamin', 'katrina', 'hosszu', 'xiaohan']\n",
    "author_list += ['urhahn','torsten', 'biemann','stephen','jaros', 'patrick', 'raymund', 'garcia', 'prashant', 'bordia']\n",
    "author_list += ['lloyd', 'restubog', 'valerie', 'caines', 'michele', 'gelfand', 'severance', 'tiane', 'bayan', 'bruss', 'janetta']\n",
    "author_list += ['abdel', 'hamid', 'latif', 'asmaa', 'ahmed', 'moghazy', 'sally', 'moustafa', 'ahmed', 'sonia', 'ghumman','marie']\n",
    "author_list += ['ryan','park', 'elisabeth', 'gilbert','trevor', 'foulk','joyce', 'bono', 'paula', 'giordano', 'patient']\n",
    "author_list += ['margarida', 'passos', 'francesco', 'sguera', 'barry', 'goldmanrussell', 'cropanzano', 'ryan','gottfredsonherman']\n",
    "author_list += ['aguinis', 'laura', 'goverlinda', 'duxbury', \"alicia\", \"grandey\", 'deborah', \"rupp\", \"brice\", 'rebecca']\n",
    "author_list += ['greenbaum', 'mawritz', 'julena', 'bonner', 'brian', 'webster', 'joseph', 'truit', 'gray', 'mawritz', 'martin']\n",
    "author_list += ['gubler', 'yves', 'guillaume', 'jeremy', 'lilian', 'otaye', 'ebede', 'woods', 'west', \"naina\", \"gupta\", 'violet']\n",
    "author_list += [\"pollack\", 'felipe','guzmanalvaro', 'espejo', 'dana','haggardhee', 'park', 'daniel', 'halgin']\n",
    "author_list += ['borgatti', 'ajay', 'mehra', 'scott', 'soltis', 'angela', 'hall', 'dwight', 'frink', 'ronald', 'buckley', 'jing']\n",
    "author_list += ['hanjuan', 'ling', \"sean\", \"hannah\", \"sumanth\", \"lester\", 'fabrice', \"cavarretta\", 'crystal','haroldbrian','holtz']\n",
    "author_list += ['brad', 'harris', 'teresa', 'cardador', 'cole', 'mistry', 'bradley', 'kirkman', 'paul', 'harveymarie','dasborough']\n",
    "author_list += ['jeffrey', 'haynie', 'mossholder', 'stanley', 'harris','ryan', 'fehr','rong', 'long','design', 'unit', 'london']\n",
    "author_list += ['school', 'economics', \"guido\", \"hertel\", 'cornelia']\n",
    "author_list += [\"rauschenbach\", 'markus', \"thielgen\", \"krumm\", 'ivona', 'hideggerben','kleef', 'higginmo', 'gerard','hodgkinsonj']\n",
    "author_list += ['kevin', 'ford', 'joeri', 'hofmans', 'edina', 'dóci', 'omar', 'solinger', 'woohee', 'timothy', 'judge']\n",
    "author_list += ['anthony', 'hood', 'bachrach', 'suzanne', 'zivnuska', 'elliot', 'bendoly', 'annekatrin', 'hoppe', 'toker', 'vivian']\n",
    "author_list += ['schachler', 'ziegler', 'matt','howardrick','jacobs', 'ryan', 'shuwei', 'hsujames','stanworth']\n",
    "author_list += ['xiaoxiao', 'huseth', 'kaplan', 'xiaoxiao', 'hujunqi','xiaoxiao', 'yujie', 'zhan', 'xiang', 'garden','huang','dina']\n",
    "author_list += ['krasikova','peter','harms', \"ronald\", \"humphrey\", 'blake', \"ashforth\", \"diefendorff\"]\n",
    "author_list += ['samuel', 'hunter', 'lily', 'cushenbery', 'jayne', 'seulki', 'jang', 'winny', 'shen', 'tammy', 'haiyan', 'zhang']\n",
    "author_list += [\"peter\", \"jennings\", \"mitchell\", \"hannah\", 'jaclyn', 'jensen', 'rubin', 'yuan', 'jiang','susan','jackson','saba']\n",
    "author_list += ['colakoglu', 'zhou', 'jiang', 'xiaowen', 'zhongmin', 'xuan', 'jiang', 'gary', 'johnsraghid']\n",
    "author_list += ['hajj', 'andrew','johnsonkatherine','roberto', 'kristen', 'jones', 'eden', 'king', 'afra', 'ahmad', 'tracy']\n",
    "author_list += ['mccausland', 'tiffani', 'chen', \"dustin\", \"jundt\", 'jason', \"huang\", 'jvanrooyen', 'gökhan', 'karagonlar']\n",
    "author_list += ['eisenberger', 'justin', 'aselage', 'olli', 'pekka', 'kauppila', 'steffen', 'kecklinda', 'babcock', 'stacey','kessler']\n",
    "author_list += ['kaitlin', 'kiburz', 'french', 'yeol', 'kyoung', 'yong','robert', 'eisenberger','kibok']\n",
    "author_list += ['baik', 'sooyeol','youngah', 'park','qikun','linn', 'dyne','stephanie','scott','kingfred','bryant', 'danielle']\n",
    "author_list += ['king','alexander', 'newman','fred', 'luthans']\n",
    "author_list += ['howard', 'klein', 'anne‐kathrin', 'kleine', 'cort', 'rudolph', 'hannes', 'zacher', 'petra', 'klumb', 'manuel']\n",
    "author_list += ['voelkle', 'siegler', 'michaela', 'knecht', 'bettina', 'wiese', 'alexandra', 'freund', 'kniffin', 'jubo', 'wansink']\n",
    "author_list += ['schulze', 'caroline', 'knight','malcolm', 'patterson','jeremy', 'dawson', 'young', 'kojin', 'choi']\n",
    "author_list += ['dohyoung','kyootai','kailash', 'joshi', \"jaclyn\", \"koopmann\", 'klodiana', \"lanaj\", 'joyce']\n",
    "author_list += [\"bono\", 'kristie', \"campana\", 'jörg', 'korff','torsten', 'biemann','sven','voelpel', 'kristof']\n",
    "author_list += ['brown', 'young', 'seong', 'degeest', 'seung', 'hong', 'mukta', 'kulkarni', \"kunze\",\"florian\",\"menges\",'jochen']\n",
    "author_list += ['florian', 'kunze','stephan','boehmheike', 'bruch', 'lauren', 'kuykendall','lydia']\n",
    "author_list += ['craig','louis','letty', 'kwanchi', 'chiu', 'jana', 'kühnel','ronald', 'bledow','nicolas']\n",
    "author_list += ['feuerhahn', 'catherine','frank', 'walter','huang', 'lance', 'frazier', 'christina', 'tupper']\n",
    "author_list += ['stav', 'fainshmidt', 'laurent', 'lapierre', 'elianne', 'steenbergen', 'maria', 'peeters', 'esther', 'kluwer']\n",
    "author_list += ['lapierre', 'laurent', 'yanhong', 'kwan', 'kwong', 'direnzo', 'shao', 'ping', 'james', 'lavelle', 'christopher', 'rupp']\n",
    "author_list += ['herda', 'randall', 'hargrove', 'meghan', 'thornton', 'lugo', 'gary', 'mcmahan', 'allan','sara', 'willis','tian', 'seth']\n",
    "author_list += ['kaplan', 'carol', 'wong', 'kwok', 'leungjie', 'wang', 'author', 'alexander', 'lewisjonathan', 'clark','yuan', 'zhang']\n",
    "author_list += ['xiao', 'ming', 'tian', 'zhaoli', 'song', 'richard', 'arvey', 'junchao', 'jason','tyler','burch','thomas','bertolt']\n",
    "author_list += ['meyer','meir', 'shemla','jürgen']\n",
    "author_list += ['wegge', 'schaubroeck', 'anita', 'keller', 'junchao', 'jason', 'barnes', 'cristiano', 'guaranalin', 'wang', 'jian']\n",
    "author_list += ['liang','crystal',  'farh','liaohui', 'chun', \"chenwei\", \"liao\", 'sandy', \"wayne\"]\n",
    "author_list += [\"rousseau\", \"weipeng\", \"wang\", \"wang\", 'dirk', 'lindebaumdeanna', 'geddes', 'dirk', 'lindebaumpeter','jordan']\n",
    "author_list += ['jukka', 'lipponen','barbara', 'wisse','jolanda', 'jetten', \"songqi\", 'aleksandra', \"luksyte\", \"zhou\",'leigh']\n",
    "author_list += ['anne','jian', 'dong', 'zhang', 'subrahmaniam', 'tangirala', 'cynthia', 'parker', 'natalia','lorinkovasara']\n",
    "author_list += ['jansen', 'perry', 'fuli', 'kwok', 'leung', 'krishna', 'savani', 'morris', 'aleksandra']\n",
    "author_list += ['luksytechristiane', 'spitzmueller', 'aleksandra', 'luksyte', 'kerrie', 'unsworth', 'avery','luria', \"luria\"]\n",
    "author_list += ['yuval', \"kalish\", 'miriam', \"weinstein\", 'luria', 'allon', 'kahana', 'judith', 'goldenberg', 'yair', 'noam']\n",
    "author_list += ['jeremy', 'mackey', 'charn', 'mcallister', 'brees', 'huang', 'jack', 'carson', 'leticia', 'maia', 'antônio', 'virgílio']\n",
    "author_list += ['bittencourt', 'bastos', 'nathanaël', 'solinger', \"muhammad\", 'abdur', 'rahman', \"malik\", 'arif', \"butt\", \"choi\"]\n",
    "author_list += ['muhammad', 'malik', 'nazir', 'butt', \"charles\", \"manz\", 'bruce', \"skaggs\", 'craig', \"pearce\", \"wassenaar\"]\n",
    "author_list += [\"mark\", \"martinko\", \"harvey\", \"mackey\", 'suzanne','masterson', 'courtney','mastersonjenny','hoobler', 'john']\n",
    "author_list += ['mathieu', \"fadel\", 'matta', 'tuğba', 'erol', 'korkmaz', 'russell', 'johnson', 'pinar']\n",
    "author_list += [\"b𝚤çaks𝚤z\", \"korkmaz\", \"johnson\", 'ella', 'miron', 'spektor', 'susannah', 'paletz', 'chun', 'rebecca']\n",
    "author_list += ['mitchellbrendan', 'boyle', 'darya', 'moghimi', 'zacher', 'susanne', 'scheibe', 'nico', 'yperen', \"tassilo\", \"momm\"]\n",
    "author_list += ['gerhard', \"blickle\", 'yongmei', 'andreas', \"wihler\", 'mareike', \"kholin\", 'jochen', \"menges\", 'francesco']\n",
    "author_list += ['montani','massimo', 'maoret','lucas', 'dufour', 'diego', 'montano', 'anna', 'reeske', 'franziska', 'franke']\n",
    "author_list += ['joachim', 'hüffmeier', 'frank','ramona', 'bobocel', 'michael','mumfordyitzhak', 'fried', 'timothy','munyonrachel']\n",
    "author_list += ['kane', 'frieder', 'charles', 'murnieks', 'anthony', 'klotz', 'teresa', 'müllercornelia']\n",
    "author_list += ['niessen', 'mohamed', 'ikram', 'nasr', 'assâad', 'akremi', 'jacqueline', 'coyle', 'shapiro', \"eitan\", \"naveh\",'katz']\n",
    "author_list += [\"navon\",\"stern\", 'thomas','nglorenzo', 'lucianetti', 'jessica','nicklinpaul','spector', 'cornelia', 'niessen', 'müller']\n",
    "author_list += ['sabine', 'hommelhoff', 'mina', 'westman', 'karen', 'nivenluke']\n",
    "author_list += ['boorman', 'norton', 'stacey', 'neal', 'ashkanasy', 'rikki', 'nouri', 'erez', 'jian', 'liang', 'brendan', 'bannister']\n",
    "author_list += ['warren', 'chiu', 'kimberly',\"brienterry\",'beehr', 'jane', \"learyjörgen\", 'sandberg', 'anna', 'carmella']\n",
    "author_list += ['ocampo', 'kohyar', 'kiazad', 'jacoba', 'oedzes', 'gerben', 'vegt', 'floor', 'rink', 'walter', 'florian', 'offergelt']\n",
    "author_list += ['klaus', 'moser', 'shaw','brian', 'holtz','seongsu','sandra', 'ohly','sabine', 'sonnentag','franziska', 'pluntke', 'hakan']\n",
    "author_list += ['ozcelik', 'youngah', 'parkverena','haun', 'youngah']\n",
    "author_list += ['parkjustin','sprung', \"vesa\", \"peltokorpi\", \"allen\", 'fabian', \"froese\",\"pengdongkyu\",'chunyan', 'pengwei', 'zeng']\n",
    "author_list += ['mark','petersontais', 'siqueira', 'barreto', 'mark', 'edward', 'pickering']\n",
    "author_list += ['matthew','piszczek', 'pollack', 'ernest', \"boyle\", 'corinne', 'post', 'roman', 'prem', 'sandra', 'ohly']\n",
    "author_list += ['kubicek', 'korunka', 'manuela', 'priesemuthregina','taylor', 'alexander', 'pundtlaura', 'venz', 'minya', 'duan']\n",
    "author_list += [\"yilong\", \"direnzo\", 'yilong', \"duan\", 'jennifer','ragsdaleterry','beehr', 'stefan', 'razinskasmartin']\n",
    "author_list += ['hoegl', 'young', 'rheejin', 'choi', 'kirsten', 'robertsonjane', \"reilly\", 'mark','roehlingjason', 'huang']\n",
    "author_list += ['jade', 'talbot', 'alex', 'rubenstein', 'kammeyer', 'mueller', 'tomas', 'thundiyil', 'jörgen', 'sandbergharidimos']\n",
    "author_list += ['tsoukas', 'carsten','schermulybertolt', 'meyer', \"pauline\", \"schilpzand\", 'irene', \"pater\", 'amir', \"erez\"]\n",
    "author_list += ['benjamin', 'schneider', 'allison', 'yost', 'kropp', 'cory', 'kind', 'holly', 'jeremy','schoen', 'selenko','mäkikangas']\n",
    "author_list += ['stride','shan','joshua', 'keller','damien', 'joseph', 'ping']\n",
    "author_list += ['shao','andrew','mary', 'mawritz', \"meir\", \"shemla\", 'bertolt', \"meyer\", 'lindred', \"greer\", 'shung']\n",
    "author_list += ['shin','feirong', 'yuan','jing', 'zhou', 'shockley', 'heather', 'ureksoy', 'ozgun', 'burcu', 'rodopman']\n",
    "author_list += ['poteat', 'ryan', 'dullaghan', 'shoham','almor','smahammad','jost']\n",
    "author_list += ['siewekebin', 'zhao', 'barjinder', 'singh', 'margaret', 'shaffer', 'selvarajan', 'adam', 'smale', 'silvia', 'bagdadli']\n",
    "author_list += ['rick', 'cotton', 'dello', 'russo', 'dickmann', 'martina', 'gianecchini', 'kaše', 'mila', 'lazarova', 'reichel', 'rozo']\n",
    "author_list += ['marijke', 'verbruggen', 'ifedapo', 'adeleye', 'maike', 'andresen', 'eleni', 'apospori', 'olusegun', 'babalola']\n",
    "author_list += ['briscoe', 'seok', 'katharina', 'chudzikowski', 'nicky', 'dries', 'petra', 'eggenhofer', 'rehart', 'zhangfeng']\n",
    "author_list += ['martin', 'gubler', 'douglas', 'svetlana', 'khapova', 'najung', 'evgenia', 'lysova', 'sergio', 'madero', 'debbie']\n",
    "author_list += ['mandel', 'wolfgang', 'mayrhofer', 'biljana', 'bogićević', 'milikić', 'sushanta', 'kumar', 'mishra', 'chikae', 'naito']\n",
    "author_list += ['emma', 'parry', 'noreen', 'saher', 'richa', 'saxena', 'nanni', 'schleicher', 'florian', 'schramm', 'pamela', 'mami']\n",
    "author_list += ['taniguchi', 'julie', 'unite']\n",
    "author_list += [\"bryan\", \"acton\",\"roseanne\", \"foti\", \"robert\", \"lord\", \"jessica\", \"gladfelter\", \"mats\"]\n",
    "author_list += [\"alvesson\",\"katja\", \"einola\", 'steina', 'jantonak', \"john\", \"antonakis\", \"samuel\", \"bendahan\", \"philippe\"]\n",
    "author_list += [\"jacquart\", \"rafael\", \"lalive\", \"george\", \"banks\", \"nicolas\", \"bastardoz\", \"michael\", \"cole\", \"david\",\"alice\"]\n",
    "author_list += [\"eagly\", \"olga\", \"epitropaki\"]\n",
    "author_list += [\"william\", \"gardner\", \".\", 'alexander', \"haslam\", \"hogg\", \"ronit\"]\n",
    "author_list += [\"kark\", \"kevin\", \"lowe\", \"philip\", \"podsakoff\", \"seth\", \"spain\", \"janka\", \"stoker\", \"niels\", \"quaquebeke\"]\n",
    "author_list += [\"mark\", \"vugt\", \"dusya\", \"vera\", \"roberto\", \"weber\", \"nicolas\", \"bastardoz\",\"mark\", \"vugt\", 'stephane']\n",
    "author_list += ['brutus', 'shawn', 'burke', 'dana', 'sims', 'elizabeth', 'lazzara', 'eduardo', 'salas', 'abraham', 'carmeli']\n",
    "author_list += ['meyrav', 'yitzack', 'halevi', \"david\", \"carrington\", \"combe\", \"mumford\", 'jingnan', 'chen', \"minyoung\", \"cheong\"]\n",
    "author_list += [\"francis\", \"yammarino\", \"shelley\", \"dionne\", \"chou\", \"tsai\",'cheng', \"steve\",\"shin\", 'guang']\n",
    "author_list += [\"liang\", \"amon\", \"chizema\",\"ganna\", \"pogrebna\", 'neil', 'stewart', \"joseph\", \"crawford\",'anne', \"kelder\", \"stéphane\"]\n",
    "author_list += [\"côté\", \"paulo\", \"lopes\", \"peter\", \"salovey\", \"christopher\", \"miners\"]\n",
    "author_list += ['uqbweave', 'david',\"david\", \"hock\", 'peng',\"belle\", \"derks\",\"colette\", \"laar\",\"naomi\", \"ellemers\", 'shelley', 'dionne']\n",
    "author_list += ['yvonne', 'budden', 'nathan',\"bassam\", \"farah\", \"rida\"]\n",
    "author_list += [\"elias\", \"cristine\", \"clercy\", \"glenn\", \"rowe\", 'christopher', 'watkins', \"louis\", \"sean\", \"hannah\", \"noel\"]\n",
    "author_list += [\"fred\", \"walumbwa\", \"zachary\", \"garfield\", \"rueden\", \"edward\", \"hagen\", 'geys', 'steffen', 'giessner']\n",
    "author_list += ['daan', 'knippenberg', 'sleebos', \"laura\", \"giurge\", \"marius\", \"dijke\", \"michelle\", \"zheng\", \"cremer\", 'design']\n",
    "author_list += ['unit', 'london', 'school', 'economics','activepdf', 'kelly', 'hannum', \"anna\", 'luca', \"heimann\"]\n",
    "author_list += [\"ingold\", \"martin\", \"kleinmann\", \"nathan\", \"hiller\", \"hock\", 'peng', \"ajay\", \"ponnapalli\", \"sibel\", \"ozgen\"]\n",
    "author_list += ['crystal', 'hoyt', 'stefanie', 'johnson', 'susan', 'elaine', 'murphy', 'kerry', 'hogue', 'skinnell', 'hendrik']\n",
    "author_list += ['huettermann', 'sebastian', 'doering', 'sabine', 'boerner', \"hughes\", \"allan\", \"tian\", \"alex\", \"newman\", \"alison\"]\n",
    "author_list += [\"legood\", 'center', 'applied', 'social', 'research', 'dongil', 'jung', 'francis', 'yammarino',\"thomas\"]\n",
    "author_list += [\"kelemen\", \"matthews\", \"kimberley\", \"breevaart\", 'michael', 'kosfeld', \"lindie\", \"liang\", \"douglas\", \"brown\"]\n",
    "author_list += [\"huiwen\", \"lian\", \"hanig\", 'lance', \"ferris\", \"lisa\", \"keeping\", \"jukka\", \"lipponen\", \"janne\", \"kaltiainen\"]\n",
    "author_list += [\"werff\", \"niklas\", \"steffens\", \"jeffrey\", \"lovelace\", \"brett\", \"neely\", \"julian\", \"allen\", \"hunter\"]\n",
    "author_list += ['bourgoin', \"charles\", \"reilly\", \"bernadette\", \"doerr\", \"caldwell\", \"jennifer\", \"chatman\", \"reilly\"]\n",
    "author_list += ['dawn', 'eubanks', \"philip\", \"podsakoff\",\"nathan\", \"podsakoff\", \"therese\", \"reitan\",\"sten\"]\n",
    "author_list += [\"stenberg\", 'chester', 'schriesheim', 'joshua', 'terri', 'scandura', 'jeroen', 'staff', \"maria\"]\n",
    "author_list += [\"tims\", \"arnold\", \"bakker\", \"despoina\", \"xanthopoulou\", \"chou\", \"tsai\", 'chih', \"wang\", 'shiuan', \"cheng\"]\n",
    "author_list += [\"herman\",\"huang\",\"wing\",'hardin','kragt','djohnston', 'billings']\n",
    "author_list += [\"fred\", \"walumbwa\", \"peng\", \"john\", \"schaubroeck\", \"bruce\", \"avolio\", 'user', \"philip\", \"yang\"]\n",
    "author_list += [\"riepe\", \"katharina\", \"moser\", \"kerstin\", \"pull\", \"siri\", \"terjesen\", \"christian\", \"zehnder\", \"holger\"]\n",
    "author_list += [\"herz\", \"jean\", 'philippe', \"bonardi\", 'school', 'business', 'msmhh']\n",
    "author_list += ['ambika', 'ambika', 'natalie', 'allen', 'tracy', 'hecht', 'neil', 'anderson', 'sarah', 'sleap', 'nikos']\n",
    "author_list += ['bozionelos', 'adam', 'butler', 'amie', 'skattebo', 'john', 'cordery', 'kevin', 'daniels', 'claire', 'harris']\n",
    "author_list += ['briner', 'taru', 'feldt', 'mika', 'kivimaumlki', 'anne', 'rantala', 'asko', 'tolvanen', 'donald', 'gardner']\n",
    "author_list += ['linn', 'dyne', 'pierce', 'filip', 'lievens', 'frederik', 'anseel', 'adam', 'meade', 'james', 'meindl']\n",
    "author_list += ['paul', 'paulus', 'karen', 'charlie', 'reeve', 'eric', 'heggestad', 'astrid', 'richardsen','zhao','zhou','jing']\n",
    "author_list += ['monica', 'martinussen', 'anit', 'somech', 'anat', 'drach', 'zahavy', 'gigi', 'sutton', 'mark', 'griffin']\n",
    "author_list += ['william', 'turnley', 'mark', 'bolino', 'scott', 'lester', 'james', 'bloodgood', 'joan', 'horn', 'toon', 'taris']\n",
    "author_list += ['wilmar', 'schaufeli', 'paul', 'schreurs', 'fred', 'walumbwa', 'peng', 'wang', 'john', 'lawler']\n",
    "author_list += ['michael', 'west', 'felix', 'brodbeck', 'andreas', 'richter', 'mark', 'wilson', 'david', 'dejoy']\n",
    "author_list += ['robert', 'vandenberg', 'hettie', 'richardson', 'allison', 'mcgrath', 'ambika','david','micheal']\n",
    "author_list += ['elena','belogolovsky','peter','bamberger','karlene','roberts','chris','bingham','campbell','seung','hwan','jeong','scott','graffin']\n",
    "author_list += ['robert','messen','andrew','carton','brice','roberts','dattée','oliver','alexy','erkko','autio','sreedhari','desai','patricio']\n",
    "author_list += ['duran','nadine','kammerlander','marc','essen','thomas','zellweger','john','joseph','wshong','gokhan','ertug','tamar','yogev']\n",
    "author_list += ['yonghoon','lee','peter','hedström','kibler','ewald','markus','perkmann','brenda','flannery','douglas','michael','florin','lubatkin']\n",
    "author_list += ['william','schulze','raghu','garud','sanjay','jain','arun','kumaraswamy','gerard','george','christopher','corbishley','jane','khayesi']\n",
    "author_list += ['martine','haas','laszlo','tihanyi','wakenshaw','gibbons','deborah','brian','gunia','joo','hun','han','saehee','kang']\n",
    "author_list += ['rebecca','kehoe','david','lepak','hausknecht','nathan','hiller','robert','vance','hitt','tina','dacin','edward','levita']\n",
    "author_list += ['jean','arregle','luc','anca','borza','fmurray','philippe','jacquart','antonakis','jason','jay','fuller','elfenbeinh','cynthia']\n",
    "author_list += ['kim','jensen','lorraine','crystal','hkpu','margaret','luciano','amy','bartels','lauren','innocenzo','travis','maynard','mathieu']\n",
    "author_list += ['hardy','smagui','johanna','mair','ignasi','marti','marc','ventresca','dellring','jcarson','mmcardle','erez','mia','mathieu']\n",
    "author_list += ['monin','niels','noorderhaven','eero','vaara','kroon','jeroen','neckebrouck','gina','dokko','lisa','hisae','nishii','sonja']\n",
    "author_list += ['opper','donde','ashmos','plowman','lakami','baker','tammy','beck','mukta','kulkarni','stephanie','solansky','deandra','villarreal']\n",
    "author_list += ['ridge','ingram','aaron','hill','bloy','drew','harry','dwight','lemke','richard','dino','staf','guillaume','soenen']\n",
    "author_list += ['tessa','melkonian','maureen','ambrose','evans','bennett','tepper','nikolaos','dimotakis','schurer','lambert','joel','koopman','fadel']\n",
    "author_list += ['matta','hee','man','park','wongun','goo','tepper','varkey','titus','owen','parker','francesca','gino','bass']\n",
    "author_list += ['erin','charlie','trevor','home','computer','martins','martín','esmt','european','varkey','gmbh','cwbauman','school','francesca','gino','bass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out the stopwords and authors names\n",
    "def filterWords(msg, words):\n",
    "    m = msg.split(' ')\n",
    "    words_end = [w + '.' for w in words]\n",
    "    filtered_words = list(filter(lambda word: word not in words, m))\n",
    "    filtered_words = [(w if w not in words_end else '.') for w in filtered_words]\n",
    "    result = ' '.join(filtered_words)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_auth = [filterWords(f, author_list) for f in pdf_p] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_proc_auth[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "stopwords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "stopwords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "stopwords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "stopwords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "stopwords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "stopwords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "stopwords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "stopwords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "stopwords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "stopwords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "stopwords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "stopwords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "stopwords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "stopwords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "stopwords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "stopwords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "stopwords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "stopwords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "stopwords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "stopwords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "stopwords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "stopwords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "stopwords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "stopwords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "stopwords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "stopwords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "stopwords += ['nevertheless', 'next', 'nine', 'no', 'nobody', 'none']\n",
    "stopwords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "stopwords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "stopwords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "stopwords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "stopwords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "stopwords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "stopwords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "stopwords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "stopwords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "stopwords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "stopwords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "stopwords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "stopwords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "stopwords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "stopwords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "stopwords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "stopwords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "stopwords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "stopwords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "stopwords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "stopwords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "stopwords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "stopwords += ['yours', 'yourself', 'yourselves']\n",
    "stopwords += ['january', 'february', 'march', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "# metadata- subject\n",
    "stopwords += ['business administration', 'economics and finance']\n",
    "# author name to remove\n",
    "stopwords +=['karina nielsen','kevin daniels','elaine', 'jaewan yang','andrew O herdman','amanda', 'sabine','kerstin','kertin','sagepub','journalspermissions','catheine','chidiebere ogbonnaya','john wiley','sons ltd','martin','jeffrey B arthur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc = [filterWords(f, stopwords) for f in data_proc_auth]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "country_list = []\n",
    "for country in pycountry.countries:\n",
    "    a = (country.name).lower()\n",
    "    country_list.append(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_country =[]\n",
    "for j in data_proc:\n",
    "    line = j\n",
    "    for k in country_list:\n",
    "        line = re.sub(k, '', line)\n",
    "        \n",
    "    data_proc_country.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_country[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #save removed title\n",
    "pickle.dump(data_proc_country, open(\"C:/Thesis/Data/save/Journal_of_organizational_behavior/metadata/removed_country/metadata_all.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors names are saved already (code is available at author name folder-get name list notebook)\n",
    "#load authors names\n",
    "import pickle\n",
    "author_nam = pickle.load(open(\"C:/Thesis/Data/save/Master_Data/auth_ref_filter_num_char/auth_Journal_of_organizational_behavior.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET REFERENCE LISTS OF STOPWORDS, I.E. WORDS THAT ARE ESSENTIALLY MEANINGLESS\n",
    "# Get all the list of authors names\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words('english') + author_nam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_1 = [filterWords(f, sw) for f in data_proc_country]  #running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_2 = [re.sub(' \\.+', ' ', f) for f in data_proc_1]\n",
    "data_proc_2 = [re.sub(' +', ' ', f) for f in data_proc_2]\n",
    "data_proc_2 = [re.sub('http', '', f) for f in data_proc_2]\n",
    "data_proc_2 = [re.sub('www', '', f) for f in data_proc_2]\n",
    "data_proc_2 = [re.sub('iweb', '', f) for f in data_proc_2]\n",
    "data_proc_2 = [re.sub(' +', ' ', f) for f in data_proc_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "pickle.dump(data_proc_2, open( \"C:/Thesis/Data/save/Master_Data/MD_4/data_proc_latest/J_OF_OB_data_proc.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import io\n",
    "with open(\"C:/Thesis/Data/save/Master_Data/MD_4/data_proc_latest/J_OF_OB_data_proc_txt.txt\", \"w\",encoding=\"utf-8\") as outfile:\n",
    "    for i in range(len(data_proc_2)):\n",
    "        outstring = \"\"\n",
    "        outstring += str(data_proc_2[i])\n",
    "        outfile.write(outstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
