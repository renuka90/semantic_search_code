{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an iterator that reads the file one line at a time instead of reading everything in memory at once\n",
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname),encoding='utf-8'):\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all txt files from the given directory\n",
    "#sentences = MySentences('C:/Thesis/Data/save/Master_Data/MD_lemmatized_ref_auth/') # a memory-friendly iterator\n",
    "sentences = MySentences('C:/Thesis/Data/save/Master_Data/MD_lemmatized_latest/') # a memory-friendly iterator\n",
    "#print(list(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list to store the sentences\n",
    "list_sent = []\n",
    "temp = [[ list_sent.append([ w for w in word.split(',') if (len(w) > 2)]) for word in s] # filtered out the short words here\n",
    "              for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob \n",
    "#from termcolor import colored, cprint \n",
    "#for i in list_sent:\n",
    "    \n",
    "  #  b = TextBlob(i) \n",
    "#print(b)\n",
    "# prints the corrected spelling \n",
    "#print (str(b.correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the word frequency of list sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(corpus):\n",
    "    result = {}\n",
    "    for data in corpus:\n",
    "        for word in data:\n",
    "            if word in result:\n",
    "                result[word] += 1 #adding result in the dictionary\n",
    "            else:\n",
    "                result[word] = 1\n",
    "\n",
    "    return result.items() #returning items\n",
    "\n",
    "#print(getWordFreq(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = getWordFreq(list_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict_items to df\n",
    "import pandas as pd\n",
    "df_fdist = pd.DataFrame.from_dict(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fdist = df_fdist.sort_values(by=[1], ascending=False)\n",
    "df = df_fdist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33800939\n"
     ]
    }
   ],
   "source": [
    "total = df_fdist[1].sum()\n",
    "print(total) # almost 34 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>employee</td>\n",
       "      <td>239477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>effect</td>\n",
       "      <td>209724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>performance</td>\n",
       "      <td>207136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>level</td>\n",
       "      <td>202324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>study</td>\n",
       "      <td>199583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50503</th>\n",
       "      <td>nfo</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17202</th>\n",
       "      <td>gerbing</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20542</th>\n",
       "      <td>marvin</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25497</th>\n",
       "      <td>baa</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100348</th>\n",
       "      <td>selloff</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0       1\n",
       "1668       employee  239477\n",
       "129          effect  209724\n",
       "1498    performance  207136\n",
       "179           level  202324\n",
       "80            study  199583\n",
       "...             ...     ...\n",
       "50503           nfo      13\n",
       "17202       gerbing      13\n",
       "20542        marvin      13\n",
       "25497           baa      13\n",
       "100348      selloff      13\n",
       "\n",
       "[27613 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the threshold to remove the certain section of vocabulary\n",
    "    \n",
    "df_threshold = df_fdist[df_fdist[1].cumsum()/df_fdist[1].sum()<0.99]\n",
    "df_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob \n",
    "#df_fdist[1].apply(lambda txt: ''.join(TextBlob(txt).correct()))\n",
    "#df_fdist['text'] = df_fdist[0].apply(lambda text: TextBlob(text).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minValue = df_threshold[1].min()\n",
    "print(minValue)\n",
    "print(len(df_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means Clustering\n",
    "Elbow method to determine the optimal number of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9['Cleaned_PaperText'] = pd.Series(texts, index = df9.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "cluster_range = range( 1, 100 )\n",
    "cluster_errors = []\n",
    "for num_clusters in cluster_range:\n",
    "    clusters = KMeans( num_clusters )\n",
    "    clusters.fit( X )\n",
    "    cluster_errors.append( clusters.inertia_ )\n",
    "clusters_df = pd.DataFrame( { \"num_clusters\":cluster_range, \"cluster_errors\": cluster_errors } )\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot( clusters_df.num_clusters, clusters_df.cluster_errors, marker = \"o\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trained with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train model {'min_count': 48, 'size': 100, 'window': 8, 'epochs': 50}\n",
    "from gensim.models import Word2Vec\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_bestpara = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14148, size=100, alpha=0.005)\n"
     ]
    }
   ],
   "source": [
    "print(model_bestpara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insert</td>\n",
       "      <td>0.411185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audiovisual</td>\n",
       "      <td>0.363597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>section</td>\n",
       "      <td>0.363573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfd</td>\n",
       "      <td>0.358088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>axis</td>\n",
       "      <td>0.343598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nexis</td>\n",
       "      <td>0.343249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>skew</td>\n",
       "      <td>0.341482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>decomposition</td>\n",
       "      <td>0.340905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>concise</td>\n",
       "      <td>0.334166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>summarizes</td>\n",
       "      <td>0.330738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  similarity\n",
       "0         insert    0.411185\n",
       "1    audiovisual    0.363597\n",
       "2        section    0.363573\n",
       "3            cfd    0.358088\n",
       "4           axis    0.343598\n",
       "5          nexis    0.343249\n",
       "6           skew    0.341482\n",
       "7  decomposition    0.340905\n",
       "8        concise    0.334166\n",
       "9     summarizes    0.330738"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(model_bestpara.wv.most_similar(positive = ['dedication'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model {'min_count': 48, 'size': 100, 'window': 8, 'epochs': 50}-- model1\n",
    "model_bestpara.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_bestpara.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train model with same parameters as of 6 articles.\n",
    "# save the word2vec model with epoch-200, size-100, window-10, min_count-70, alpha-0.005\n",
    "#******************************\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_modified = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=10, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=70, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "#model1.train(sentences, total_examples=len(sentences), epochs=200) # epochs is the number of iterations over the full data set to train the model\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_modified.wv.most_similar(positive = ['hrm'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with epoch-200, size-100, window-10, min_count-70, alpha-0.005  -- model:2\n",
    "model_modified.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_modified.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation based on the observation table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 27.283753633499146 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-1\n",
    "# initialize and train model {'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=50\n",
    "sentences = list_sent\n",
    "model_obser_1 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=75, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=7, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.977402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allocation</td>\n",
       "      <td>0.976516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demand</td>\n",
       "      <td>0.968174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>effort</td>\n",
       "      <td>0.967755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>motivates</td>\n",
       "      <td>0.967653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>threaten</td>\n",
       "      <td>0.966332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>consume</td>\n",
       "      <td>0.965459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>involvement</td>\n",
       "      <td>0.963354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>encourage</td>\n",
       "      <td>0.960911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>consumes</td>\n",
       "      <td>0.960707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  similarity\n",
       "0       energy    0.977402\n",
       "1   allocation    0.976516\n",
       "2       demand    0.968174\n",
       "3       effort    0.967755\n",
       "4    motivates    0.967653\n",
       "5     threaten    0.966332\n",
       "6      consume    0.965459\n",
       "7  involvement    0.963354\n",
       "8    encourage    0.960911\n",
       "9     consumes    0.960707"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_1.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50} observation 1\n",
    "model_obser_1.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_1.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 70.70103406906128 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# model-2\n",
    "# initialize and train model {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_obser_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=70, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enable</td>\n",
       "      <td>0.527002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>effort</td>\n",
       "      <td>0.505735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>persistent</td>\n",
       "      <td>0.496096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>involvement</td>\n",
       "      <td>0.487881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stimulate</td>\n",
       "      <td>0.484856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>library</td>\n",
       "      <td>0.471846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>enhance</td>\n",
       "      <td>0.470841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaptivity</td>\n",
       "      <td>0.469507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>worksite</td>\n",
       "      <td>0.468392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>implementation</td>\n",
       "      <td>0.467108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  similarity\n",
       "0          enable    0.527002\n",
       "1          effort    0.505735\n",
       "2      persistent    0.496096\n",
       "3     involvement    0.487881\n",
       "4       stimulate    0.484856\n",
       "5         library    0.471846\n",
       "6         enhance    0.470841\n",
       "7      adaptivity    0.469507\n",
       "8        worksite    0.468392\n",
       "9  implementation    0.467108"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_2.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}observation 2\n",
    "model_obser_2.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 52.922818422317505 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-3\n",
    "# initialize and train model {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_obser_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14148, size=150, alpha=0.005)\n"
     ]
    }
   ],
   "source": [
    "print(model_obser_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synergy</td>\n",
       "      <td>0.752372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programme</td>\n",
       "      <td>0.732433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discrimination</td>\n",
       "      <td>0.668144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset</td>\n",
       "      <td>0.618216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calculates</td>\n",
       "      <td>0.599232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>prohibits</td>\n",
       "      <td>0.597760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voluntary</td>\n",
       "      <td>0.574030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equip</td>\n",
       "      <td>0.569700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>minority</td>\n",
       "      <td>0.560853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.558599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  similarity\n",
       "0         synergy    0.752372\n",
       "1       programme    0.732433\n",
       "2  discrimination    0.668144\n",
       "3           asset    0.618216\n",
       "4      calculates    0.599232\n",
       "5       prohibits    0.597760\n",
       "6       voluntary    0.574030\n",
       "7           equip    0.569700\n",
       "8        minority    0.560853\n",
       "9   multicultural    0.558599"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_3.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_3.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest updated model- 3 observations freezing all the hyperparameters except window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 46.44149398803711 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_1 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=8, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synergy</td>\n",
       "      <td>0.780414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programme</td>\n",
       "      <td>0.734479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.684074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.645586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discrimination</td>\n",
       "      <td>0.639988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>impactful</td>\n",
       "      <td>0.622932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>prohibits</td>\n",
       "      <td>0.596265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>asset</td>\n",
       "      <td>0.591436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>csr</td>\n",
       "      <td>0.590010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>perspective</td>\n",
       "      <td>0.573124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  similarity\n",
       "0         synergy    0.780414\n",
       "1       programme    0.734479\n",
       "2         teenage    0.684074\n",
       "3   multicultural    0.645586\n",
       "4  discrimination    0.639988\n",
       "5       impactful    0.622932\n",
       "6       prohibits    0.596265\n",
       "7           asset    0.591436\n",
       "8             csr    0.590010\n",
       "9     perspective    0.573124"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_1.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_1.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 54.83220028877258 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-2\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=12, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synergy</td>\n",
       "      <td>0.778583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programme</td>\n",
       "      <td>0.740670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discrimination</td>\n",
       "      <td>0.662560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asset</td>\n",
       "      <td>0.612744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prohibits</td>\n",
       "      <td>0.608484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.598837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>teenage</td>\n",
       "      <td>0.594525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>equip</td>\n",
       "      <td>0.579206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>elimination</td>\n",
       "      <td>0.573388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>voluntary</td>\n",
       "      <td>0.566649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  similarity\n",
       "0         synergy    0.778583\n",
       "1       programme    0.740670\n",
       "2  discrimination    0.662560\n",
       "3           asset    0.612744\n",
       "4       prohibits    0.608484\n",
       "5   multicultural    0.598837\n",
       "6         teenage    0.594525\n",
       "7           equip    0.579206\n",
       "8     elimination    0.573388\n",
       "9       voluntary    0.566649"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_2.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 54.96534776687622 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Model-3\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=16, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enable</td>\n",
       "      <td>0.527047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>persistent</td>\n",
       "      <td>0.520092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effort</td>\n",
       "      <td>0.511320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>library</td>\n",
       "      <td>0.503256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>0.491080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adaptivity</td>\n",
       "      <td>0.489512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>involvement</td>\n",
       "      <td>0.485876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>recovery</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adepartment</td>\n",
       "      <td>0.475325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>implementation</td>\n",
       "      <td>0.474197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  similarity\n",
       "0          enable    0.527047\n",
       "1      persistent    0.520092\n",
       "2          effort    0.511320\n",
       "3         library    0.503256\n",
       "4    surveillance    0.491080\n",
       "5      adaptivity    0.489512\n",
       "6     involvement    0.485876\n",
       "7        recovery    0.480000\n",
       "8     adepartment    0.475325\n",
       "9  implementation    0.474197"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_3.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_3.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "model_fasttext = FastText(size=75, window=7, min_count=50, sentences=list_sent, iter=50)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['turnover'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}observation 1\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_1.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_2 = FastText(size=100, window=15, min_count=70, sentences=list_sent, iter=200)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200} observation 2\n",
    "model_fasttext_2.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_2.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_3 = FastText(size=150, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_3.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation  for primary words diversity, empowerment, engagement and climate based on different vector dimension size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 94.2230167388916 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 75\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_75 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=75, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaptivity</td>\n",
       "      <td>0.567759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>invaluable</td>\n",
       "      <td>0.519621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>domaing</td>\n",
       "      <td>0.515985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.479426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>0.479384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>champion</td>\n",
       "      <td>0.473263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oregon</td>\n",
       "      <td>0.469937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>periodical</td>\n",
       "      <td>0.469288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>portland</td>\n",
       "      <td>0.462311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spiritual</td>\n",
       "      <td>0.455308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  similarity\n",
       "0     adaptivity    0.567759\n",
       "1     invaluable    0.519621\n",
       "2        domaing    0.515985\n",
       "3  multicultural    0.479426\n",
       "4          chair    0.479384\n",
       "5       champion    0.473263\n",
       "6         oregon    0.469937\n",
       "7     periodical    0.469288\n",
       "8       portland    0.462311\n",
       "9      spiritual    0.455308"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_75.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_75.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_75.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 99.96387577056885 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 100\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_100 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaptivity</td>\n",
       "      <td>0.561197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domaing</td>\n",
       "      <td>0.509782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invaluable</td>\n",
       "      <td>0.495539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.490148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>0.455568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>champion</td>\n",
       "      <td>0.455383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>workfamily</td>\n",
       "      <td>0.450441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>portland</td>\n",
       "      <td>0.448808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oregon</td>\n",
       "      <td>0.447884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mentor</td>\n",
       "      <td>0.443087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  similarity\n",
       "0     adaptivity    0.561197\n",
       "1        domaing    0.509782\n",
       "2     invaluable    0.495539\n",
       "3  multicultural    0.490148\n",
       "4          chair    0.455568\n",
       "5       champion    0.455383\n",
       "6     workfamily    0.450441\n",
       "7       portland    0.448808\n",
       "8         oregon    0.447884\n",
       "9         mentor    0.443087"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_100.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_100.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_100.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 106.18697094917297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 150\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_150 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adaptivity</td>\n",
       "      <td>0.555440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domaing</td>\n",
       "      <td>0.519504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>invaluable</td>\n",
       "      <td>0.482566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multicultural</td>\n",
       "      <td>0.478398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>0.469153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>champion</td>\n",
       "      <td>0.465655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>periodical</td>\n",
       "      <td>0.436557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mentor</td>\n",
       "      <td>0.435273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oregon</td>\n",
       "      <td>0.426130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>portland</td>\n",
       "      <td>0.425120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  similarity\n",
       "0     adaptivity    0.555440\n",
       "1        domaing    0.519504\n",
       "2     invaluable    0.482566\n",
       "3  multicultural    0.478398\n",
       "4          chair    0.469153\n",
       "5       champion    0.465655\n",
       "6     periodical    0.436557\n",
       "7         mentor    0.435273\n",
       "8         oregon    0.426130\n",
       "9       portland    0.425120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_150.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_150.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_150.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1196.5456109046936 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_75 = FastText(size=75, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climateg</td>\n",
       "      <td>0.947593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climb</td>\n",
       "      <td>0.793193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animate</td>\n",
       "      <td>0.702181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip</td>\n",
       "      <td>0.578999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intimate</td>\n",
       "      <td>0.507553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ultimate</td>\n",
       "      <td>0.495731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mate</td>\n",
       "      <td>0.481111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>teammate</td>\n",
       "      <td>0.457302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>approximate</td>\n",
       "      <td>0.439182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cliff</td>\n",
       "      <td>0.428637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  similarity\n",
       "0     climateg    0.947593\n",
       "1        climb    0.793193\n",
       "2      animate    0.702181\n",
       "3         clip    0.578999\n",
       "4     intimate    0.507553\n",
       "5     ultimate    0.495731\n",
       "6         mate    0.481111\n",
       "7     teammate    0.457302\n",
       "8  approximate    0.439182\n",
       "9        cliff    0.428637"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_75.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_75.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_75.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 976.479766368866 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_100 = FastText(size=100, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climateg</td>\n",
       "      <td>0.949268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climb</td>\n",
       "      <td>0.773934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animate</td>\n",
       "      <td>0.700782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip</td>\n",
       "      <td>0.535080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intimate</td>\n",
       "      <td>0.500857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>teammate</td>\n",
       "      <td>0.474088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ultimate</td>\n",
       "      <td>0.464241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mate</td>\n",
       "      <td>0.445071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cliff</td>\n",
       "      <td>0.412281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>approximate</td>\n",
       "      <td>0.409533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  similarity\n",
       "0     climateg    0.949268\n",
       "1        climb    0.773934\n",
       "2      animate    0.700782\n",
       "3         clip    0.535080\n",
       "4     intimate    0.500857\n",
       "5     teammate    0.474088\n",
       "6     ultimate    0.464241\n",
       "7         mate    0.445071\n",
       "8        cliff    0.412281\n",
       "9  approximate    0.409533"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_100.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_100.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_100.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 39530.89315152168 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_150 = FastText(size=150, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climateg</td>\n",
       "      <td>0.940577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climb</td>\n",
       "      <td>0.782772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animate</td>\n",
       "      <td>0.702102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip</td>\n",
       "      <td>0.569480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intimate</td>\n",
       "      <td>0.558011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mate</td>\n",
       "      <td>0.531406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ultimate</td>\n",
       "      <td>0.525396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>teammate</td>\n",
       "      <td>0.468850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proximate</td>\n",
       "      <td>0.429999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cliff</td>\n",
       "      <td>0.407638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  similarity\n",
       "0   climateg    0.940577\n",
       "1      climb    0.782772\n",
       "2    animate    0.702102\n",
       "3       clip    0.569480\n",
       "4   intimate    0.558011\n",
       "5       mate    0.531406\n",
       "6   ultimate    0.525396\n",
       "7   teammate    0.468850\n",
       "8  proximate    0.429999\n",
       "9      cliff    0.407638"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_150.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_150.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_150.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/paraModified/fasttext/save_fasttext_model_12_articles.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg- either 1 or 0. 1 means to train a skip-gram model and 0 means to train a CBOW model.\n",
    "# hs- either 1 or 0. if this is 1, ten hierarchical softmax will be used as the loss function.\n",
    "# workers- number of threads for training\n",
    "# iter- number of iterations over the samples\n",
    "# size- the dimensions of the word vectors and hence must be an integer.\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "model_fasttext = FastText(list_sent, sg=1, hs=1, size=100, workers=12, iter=200, min_count=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['leadership'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['turnover'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['selection'], topn=20), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the word2vec model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/save_fasttext_model_12_articles.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from glove import Corpus, Glove\n",
    "from glove import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Creating a corpus object\n",
    "corpus = Corpus() \n",
    "\n",
    "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=10)\n",
    "\n",
    "glove = Glove(no_components=5, learning_rate=0.05) \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "#glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation : Wordsim353\n",
    "wordsim is a way of measuring how a model captures similarity, rather than relatedness or association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "similarities = model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simlex999\n",
    "Measuring how a model captures the relateness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related = model.wv.evaluate_word_pairs(datapath('simlex999.txt'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ones you want\n",
    "df1 = df[['word']]\n",
    "t = len(df1['word'])\n",
    "if t < 4:\n",
    "    print(\"yees\")\n",
    "else:\n",
    "    print(\"noo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'a': [1, 10, 8, 11, -1],\n",
    "                       'b': list('abdce'),\n",
    "                       'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
    "df_test.nlargest(3, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[df.nlargest(3,'similarity'),'word']= 'background-color: yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame.drop\n",
    "df.drop(df.columns[[1, 2]], axis=1, inplace=True)\n",
    "\n",
    "# drop by Name\n",
    "df1 = df1.drop(['B', 'C'], axis=1)\n",
    "\n",
    "# Select the ones you want\n",
    "df1 = df[['a','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = []\n",
    "count = 0\n",
    "max_count = 50\n",
    "X = np.zeros(shape=(max_count,len(model['model'])))\n",
    "\n",
    "for term in model.wv.vocab:\n",
    "    X[count] = model[term]\n",
    "    labels.append(term)\n",
    "    count+= 1\n",
    "    if count >= max_count: break\n",
    "\n",
    "# It is recommended to use PCA first to reduce to ~50 dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_50 = pca.fit_transform(X)\n",
    "\n",
    "# Using TSNE to further reduce to 2 dimensions\n",
    "from sklearn.manifold import TSNE\n",
    "model_tsne = TSNE(n_components=2, random_state=0)\n",
    "Y = model_tsne.fit_transform(X_50)\n",
    "\n",
    "# Show the scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y[:,0], Y[:,1], 20)\n",
    "\n",
    "\n",
    "\n",
    "# Add labels\n",
    "for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
    "    plt.annotate(label, xy = (x,y), xytext = (0, 0), textcoords = 'offset points', size = 10)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/fastText/ft_model_with_6_articles.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlight Specific Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "df = pd.DataFrame(model.wv.most_similar(positive = ['leadership'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_col(x):\n",
    "    c1 = 'background-color: yellow'\n",
    "    c3 = 'background-color: #FFFF9E'\n",
    "    c2 = ''\n",
    "    temp = x['similarity']>0.6\n",
    "    temp2 = (x['similarity'] < 0.6)\n",
    "    \n",
    "    df1 = pd.DataFrame(c2, index=df.index, columns = df.columns)\n",
    "    \n",
    "    df1.loc[temp,'word'] = c1\n",
    "    df1.loc[temp2,'word'] = c3\n",
    "    \n",
    "    return df1\n",
    "df.style.apply(select_col,axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
