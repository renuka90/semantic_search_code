{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an iterator that reads the file one line at a time instead of reading everything in memory at once\n",
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname),encoding='utf-8'):\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all txt files from the given directory\n",
    "#sentences = MySentences('C:/Thesis/Data/save/Master_Data/MD_lemmatized_ref_auth/') # a memory-friendly iterator\n",
    "sentences = MySentences('C:/Thesis/Data/save/Master_Data/MD_lemmatized_latest/') # a memory-friendly iterator\n",
    "#print(list(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list to store the sentences\n",
    "list_sent = []\n",
    "temp = [[ list_sent.append([ w for w in word.split(',') if (len(w) > 2)]) for word in s] # filtered out the short words here\n",
    "              for s in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest updated model\n",
    "3 observations: freezing all the hyperparameters except window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 51.38155460357666 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Model 1\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_1 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=8, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transformational</td>\n",
       "      <td>0.693962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convene</td>\n",
       "      <td>0.649892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adler</td>\n",
       "      <td>0.637411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>style</td>\n",
       "      <td>0.607412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>servant</td>\n",
       "      <td>0.596838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lecture</td>\n",
       "      <td>0.593236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>greenwich</td>\n",
       "      <td>0.582595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bass</td>\n",
       "      <td>0.578563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>facilitation</td>\n",
       "      <td>0.577453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>farmer</td>\n",
       "      <td>0.577441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  similarity\n",
       "0  transformational    0.693962\n",
       "1           convene    0.649892\n",
       "2             adler    0.637411\n",
       "3             style    0.607412\n",
       "4           servant    0.596838\n",
       "5           lecture    0.593236\n",
       "6         greenwich    0.582595\n",
       "7              bass    0.578563\n",
       "8      facilitation    0.577453\n",
       "9            farmer    0.577441"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_1.wv.most_similar(positive = ['leadership'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_1.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 63.24367833137512 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Model-2\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=12, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perfectly</td>\n",
       "      <td>0.329192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fly</td>\n",
       "      <td>0.317525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maximally</td>\n",
       "      <td>0.314413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inform</td>\n",
       "      <td>0.313620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reputational</td>\n",
       "      <td>0.305158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boudreau</td>\n",
       "      <td>0.289132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>downplay</td>\n",
       "      <td>0.288628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>brain</td>\n",
       "      <td>0.286859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>inseparable</td>\n",
       "      <td>0.285406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>indispensable</td>\n",
       "      <td>0.282179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  similarity\n",
       "0      perfectly    0.329192\n",
       "1            fly    0.317525\n",
       "2      maximally    0.314413\n",
       "3         inform    0.313620\n",
       "4   reputational    0.305158\n",
       "5       boudreau    0.289132\n",
       "6       downplay    0.288628\n",
       "7          brain    0.286859\n",
       "8    inseparable    0.285406\n",
       "9  indispensable    0.282179"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_2.wv.most_similar(positive = ['hrm'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_2.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 52.564780712127686 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#Model-3\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=16, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaken</td>\n",
       "      <td>0.561579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>0.554176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overqualification</td>\n",
       "      <td>0.549831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speculate</td>\n",
       "      <td>0.536174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>steep</td>\n",
       "      <td>0.529910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deprivation</td>\n",
       "      <td>0.516588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>overqualified</td>\n",
       "      <td>0.513957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>predictive</td>\n",
       "      <td>0.509146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cultivate</td>\n",
       "      <td>0.508110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>absenteeism</td>\n",
       "      <td>0.487167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word  similarity\n",
       "0             weaken    0.561579\n",
       "1          satisfied    0.554176\n",
       "2  overqualification    0.549831\n",
       "3          speculate    0.536174\n",
       "4              steep    0.529910\n",
       "5        deprivation    0.516588\n",
       "6      overqualified    0.513957\n",
       "7         predictive    0.509146\n",
       "8          cultivate    0.508110\n",
       "9        absenteeism    0.487167"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_3.wv.most_similar(positive = ['satisfaction'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_3.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "model_fasttext = FastText(size=75, window=7, min_count=100, sentences=list_sent, iter=50)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['turnover'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}observation 1\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_1.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_2 = FastText(size=100, window=15, min_count=100, sentences=list_sent, iter=200)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200} observation 2\n",
    "model_fasttext_2.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_2.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_3 = FastText(size=150, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_3.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_3.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
