{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I revised this one! It now reads only one file, line-based\n",
    "# make an iterator that reads the file one line at a time instead of reading everything in memory at once\n",
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename,encoding='utf-8'):\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = MySentences('C:/Thesis/Data/save/Master_Data/MD_lemmatized_ref_auth/') # a memory-friendly iterator\n",
    "sentences = MySentences('C:/Thesis/Data/save/Master_Data/lemmatized_data/data_lemmatized.txt') # a memory-friendly iterator\n",
    "\n",
    "# NOTE:\n",
    "# sentences is now kept as a memory-friendly iterator and the contents of the txt file are now NEVER fully loaded into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the word frequency of list sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(corpus):\n",
    "    result = {}\n",
    "    for data in corpus:\n",
    "        for word in data:\n",
    "            if word in result:\n",
    "                result[word] += 1 #adding result in the dictionary\n",
    "            else:\n",
    "                result[word] = 1\n",
    "\n",
    "    return result #returning full dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = getWordFreq(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether given key already exists in a dictionary. \n",
    "def checkKey(dict, key): \n",
    "      \n",
    "    if key in dict.keys(): \n",
    "        print(\"Present, \", end =\" \") \n",
    "        print(\"value =\", dict[key]) \n",
    "    else: \n",
    "        print(\"Not present\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present,  value = 93\n"
     ]
    }
   ],
   "source": [
    "key = 'engagement'\n",
    "checkKey(fdist1, key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict to df\n",
    "import pandas as pd\n",
    "df_fdist = pd.DataFrame.from_dict(fdist1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fdist = df_fdist.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the threshold to remove the certain section of vocabulary\n",
    "theta = 0.96    \n",
    "df_threshold = df_fdist[df_fdist[0].cumsum()/df_fdist[0].sum() < theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "6761\n"
     ]
    }
   ],
   "source": [
    "minValue = df_threshold[0].min()\n",
    "print(minValue)\n",
    "print(len(df_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some memory clean-up\n",
    "del fdist1\n",
    "del df_fdist\n",
    "del df_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trained with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train model {'min_count': 48, 'size': 100, 'window': 8, 'epochs': 50}\n",
    "from gensim.models import Word2Vec\n",
    "epochs=200\n",
    "#sentences = list_sent\n",
    "model_bestpara = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=minValue, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_bestpara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dissatisfaction</td>\n",
       "      <td>0.559937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insecurity</td>\n",
       "      <td>0.502478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attitude</td>\n",
       "      <td>0.489941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>performance</td>\n",
       "      <td>0.483670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affective</td>\n",
       "      <td>0.467869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>satis</td>\n",
       "      <td>0.449520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happiness</td>\n",
       "      <td>0.445725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attitudinal</td>\n",
       "      <td>0.437997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.429678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>manager-rated</td>\n",
       "      <td>0.426777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  similarity\n",
       "0  dissatisfaction    0.559937\n",
       "1       insecurity    0.502478\n",
       "2         attitude    0.489941\n",
       "3      performance    0.483670\n",
       "4        affective    0.467869\n",
       "5            satis    0.449520\n",
       "6        happiness    0.445725\n",
       "7      attitudinal    0.437997\n",
       "8       depression    0.429678\n",
       "9    manager-rated    0.426777"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "pd.DataFrame(model_bestpara.wv.most_similar(positive = ['satisfaction'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 96% percentile \n",
    "model_bestpara.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model1_96_percentile.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 95% percentile\n",
    "model_bestpara.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model1.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_bestpara.save('F:/Data-UvA-Large/model_jom_JdG.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JORNT: I DID NOT USE ANY OF THE CODE FROM THIS POINT FORWARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and train model {'min_count': 48, 'size': 100, 'window': 8, 'epochs': 50}\n",
    "from gensim.models import Word2Vec\n",
    "epochs=200\n",
    "#sentences = list_sent\n",
    "model_bestpara_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=7, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=minValue, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bestpara_2.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 96% percentile \n",
    "model_bestpara_2.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model2_96_percentile.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "epochs=200\n",
    "#sentences = list_sent\n",
    "model_bestpara_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=11, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=minValue, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bestpara_3.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with 96% percentile \n",
    "model_bestpara_3.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model3_96_percentile.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize and train model with same parameters as of 6 articles.\n",
    "# save the word2vec model with epoch-200, size-100, window-10, min_count-70, alpha-0.005\n",
    "#******************************\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_modified = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=10, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=70, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "#model1.train(sentences, total_examples=len(sentences), epochs=200) # epochs is the number of iterations over the full data set to train the model\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_modified.wv.most_similar(positive = ['hrm'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with epoch-200, size-100, window-10, min_count-70, alpha-0.005  -- model:2\n",
    "model_modified.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_modified.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation based on the observation table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-1\n",
    "# initialize and train model {'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=50\n",
    "sentences = list_sent\n",
    "model_obser_1 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=75, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=7, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_1.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50} observation 1\n",
    "model_obser_1.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_1.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-2\n",
    "# initialize and train model {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_obser_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=70, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_2.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}observation 2\n",
    "model_obser_2.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-3\n",
    "# initialize and train model {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_obser_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_obser_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_3.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_3.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_latest/model_obser_3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latest updated model- 3 observations freezing all the hyperparameters except window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_1 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=8, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_1.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_1.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-2\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_2 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=12, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_2.wv.most_similar(positive = ['diversity'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_2.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model-3\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=200\n",
    "sentences = list_sent\n",
    "model_3 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=16, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=50, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_3.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_3.save('C:/Thesis/Data/save/Master_Data/Model/word2vecWithDifferentWS/model_3.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22944.82331967354 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#{'min_count': 50, 'size':75 , 'window': 7, 'epochs': 50}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "epochs = 200\n",
    "model_fasttext = FastText(size=100, window=15, min_count=minValue, sentences=sentences, iter=epochs)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['turnover'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}observation 1\n",
    "# model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_1.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/latest/fastText/model_1_fasttext.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 25501.265021800995 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs = 200\n",
    "model_fasttext_2 = FastText(size=100, window=7, min_count=minValue, sentences=sentences, iter=epochs)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrm</td>\n",
       "      <td>0.675980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpws</td>\n",
       "      <td>0.597755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>practice</td>\n",
       "      <td>0.594471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ihrm</td>\n",
       "      <td>0.551434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corporatvernance</td>\n",
       "      <td>0.504233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>high-performance</td>\n",
       "      <td>0.502931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>strategic</td>\n",
       "      <td>0.496251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bundle</td>\n",
       "      <td>0.491381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>firm-level</td>\n",
       "      <td>0.489344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hphrps</td>\n",
       "      <td>0.484543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  similarity\n",
       "0              shrm    0.675980\n",
       "1              hpws    0.597755\n",
       "2          practice    0.594471\n",
       "3              ihrm    0.551434\n",
       "4  corporatvernance    0.504233\n",
       "5  high-performance    0.502931\n",
       "6         strategic    0.496251\n",
       "7            bundle    0.491381\n",
       "8        firm-level    0.489344\n",
       "9            hphrps    0.484543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_2.wv.most_similar(positive = ['hrm'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 70, 'size':100 , 'window': 15, 'epochs': 200} observation 2\n",
    "# model_fasttext_2.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_2.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fasttext_2.save('C:/Thesis/Data/save/Master_Data/Model/latest/fastText/model_2_fasttext.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "epochs = 200\n",
    "model_fasttext_3 = FastText(size=100, window=11, min_count=minValue, sentences=sentences, iter=epochs)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['engagement'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "# model_fasttext_3.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_latest/model_fasttext_3.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fasttext_3.save('C:/Thesis/Data/save/Master_Data/Model/latest/fastText/model_3_fasttext.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation  for primary words diversity, empowerment, engagement and climate based on different vector dimension size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 75\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_75 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=75, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_75.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_75.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_75.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 100\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_100 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_100.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_100.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_100.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-3 remain the standard model but with different vector dimentsion size\n",
    "# For Size = 150\n",
    "# initialize and train model {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "epochs=300\n",
    "sentences = list_sent\n",
    "model_obser_150 = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=150, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=20, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=100, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_obser_150.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_obser_150.save('C:/Thesis/Data/save/Master_Data/Model/word2vec_different_size/model_obser_150.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_75 = FastText(size=75, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_75.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':75 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_75.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_75.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_100 = FastText(size=100, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_100.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':100 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_100.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_100.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300}\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model_fasttext_150 = FastText(size=150, window=20, min_count=100, sentences=list_sent, iter=300)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext_150.wv.most_similar(positive = ['climate'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fasttext model with {'min_count': 100, 'size':150 , 'window': 20, 'epochs': 300} observation 3\n",
    "model_fasttext_150.save('C:/Thesis/Data/save/Master_Data/Model/fasttext_different_size/model_fasttext_150.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#*********************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/paraModified/fasttext/save_fasttext_model_12_articles.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sg- either 1 or 0. 1 means to train a skip-gram model and 0 means to train a CBOW model.\n",
    "# hs- either 1 or 0. if this is 1, ten hierarchical softmax will be used as the loss function.\n",
    "# workers- number of threads for training\n",
    "# iter- number of iterations over the samples\n",
    "# size- the dimensions of the word vectors and hence must be an integer.\n",
    "\n",
    "from gensim.models.fasttext import FastText\n",
    "model_fasttext = FastText(list_sent, sg=1, hs=1, size=100, workers=12, iter=200, min_count=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['leadership'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['turnover'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "pd.DataFrame(model_fasttext.wv.most_similar(positive = ['selection'], topn=20), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the word2vec model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/save_fasttext_model_12_articles.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Glove "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from glove import Corpus, Glove\n",
    "from glove import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Creating a corpus object\n",
    "corpus = Corpus() \n",
    "\n",
    "#Training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=10)\n",
    "\n",
    "glove = Glove(no_components=5, learning_rate=0.05) \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "#glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation : Wordsim353\n",
    "wordsim is a way of measuring how a model captures similarity, rather than relatedness or association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "similarities = model.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simlex999\n",
    "Measuring how a model captures the relateness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "related = model.wv.evaluate_word_pairs(datapath('simlex999.txt'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the ones you want\n",
    "df1 = df[['word']]\n",
    "t = len(df1['word'])\n",
    "if t < 4:\n",
    "    print(\"yees\")\n",
    "else:\n",
    "    print(\"noo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'a': [1, 10, 8, 11, -1],\n",
    "                       'b': list('abdce'),\n",
    "                       'c': [1.0, 2.0, np.nan, 3.0, 4.0]})\n",
    "df_test.nlargest(3, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[df.nlargest(3,'similarity'),'word']= 'background-color: yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using DataFrame.drop\n",
    "df.drop(df.columns[[1, 2]], axis=1, inplace=True)\n",
    "\n",
    "# drop by Name\n",
    "df1 = df1.drop(['B', 'C'], axis=1)\n",
    "\n",
    "# Select the ones you want\n",
    "df1 = df[['a','d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels = []\n",
    "count = 0\n",
    "max_count = 50\n",
    "X = np.zeros(shape=(max_count,len(model['model'])))\n",
    "\n",
    "for term in model.wv.vocab:\n",
    "    X[count] = model[term]\n",
    "    labels.append(term)\n",
    "    count+= 1\n",
    "    if count >= max_count: break\n",
    "\n",
    "# It is recommended to use PCA first to reduce to ~50 dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "X_50 = pca.fit_transform(X)\n",
    "\n",
    "# Using TSNE to further reduce to 2 dimensions\n",
    "from sklearn.manifold import TSNE\n",
    "model_tsne = TSNE(n_components=2, random_state=0)\n",
    "Y = model_tsne.fit_transform(X_50)\n",
    "\n",
    "# Show the scatter plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(Y[:,0], Y[:,1], 20)\n",
    "\n",
    "\n",
    "\n",
    "# Add labels\n",
    "for label, x, y in zip(labels, Y[:, 0], Y[:, 1]):\n",
    "    plt.annotate(label, xy = (x,y), xytext = (0, 0), textcoords = 'offset points', size = 10)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_fasttext.save('C:/Thesis/Data/save/Master_Data/Model/fastText/ft_model_with_6_articles.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlight Specific Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# get an example from the model: find single terms that are alike [positive] or dissimilar [negative] to specified reference words\n",
    "df = pd.DataFrame(model.wv.most_similar(positive = ['leadership'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_col(x):\n",
    "    c1 = 'background-color: yellow'\n",
    "    c3 = 'background-color: #FFFF9E'\n",
    "    c2 = ''\n",
    "    temp = x['similarity']>0.6\n",
    "    temp2 = (x['similarity'] < 0.6)\n",
    "    \n",
    "    df1 = pd.DataFrame(c2, index=df.index, columns = df.columns)\n",
    "    \n",
    "    df1.loc[temp,'word'] = c1\n",
    "    df1.loc[temp2,'word'] = c3\n",
    "    \n",
    "    return df1\n",
    "df.style.apply(select_col,axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
