{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all text Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  line-based iterator that reads the file one line at a time instead of reading everything in memory at once\n",
    "import os\n",
    "class MySentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    " \n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename,encoding='utf-8'):\n",
    "            yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a memory-friendly iterator\n",
    "sentences = MySentences('C:/Thesis/Data/save/Master_Data/lemmatized_data/data_lemmatized.txt') # a memory-friendly iterator\n",
    "\n",
    "# NOTE:\n",
    "# sentences is now kept as a memory-friendly iterator and the contents of the txt file are now NEVER fully loaded into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the word frequency of list sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordFreq(corpus):\n",
    "    result = {}\n",
    "    for data in corpus:\n",
    "        for word in data:\n",
    "            if word in result:\n",
    "                result[word] += 1 #adding result in the dictionary\n",
    "            else:\n",
    "                result[word] = 1\n",
    "\n",
    "    return result #returning full dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = getWordFreq(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether given key already exists in a dictionary. \n",
    "def checkKey(dict, key): \n",
    "      \n",
    "    if key in dict.keys(): \n",
    "        print(\"Present, \", end =\" \") \n",
    "        print(\"value =\", dict[key]) \n",
    "    else: \n",
    "        print(\"Not present\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present,  value = 93\n"
     ]
    }
   ],
   "source": [
    "key = 'engagement'\n",
    "checkKey(fdist1, key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict to df\n",
    "import pandas as pd\n",
    "df_fdist = pd.DataFrame.from_dict(fdist1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fdist = df_fdist.sort_values(by=[0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the threshold to remove the certain section of vocabulary\n",
    "theta = 0.96    \n",
    "df_threshold = df_fdist[df_fdist[0].cumsum()/df_fdist[0].sum() < theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "6761\n"
     ]
    }
   ],
   "source": [
    "minValue = df_threshold[0].min()\n",
    "print(minValue)\n",
    "print(len(df_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some memory clean-up\n",
    "del fdist1\n",
    "del df_fdist\n",
    "del df_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trained with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "epochs=200\n",
    "#sentences = list_sent\n",
    "model_bestpara = Word2Vec(\n",
    "        sentences, # our dataset\n",
    "        size=100, # this is the length of the vector to numerically represent the \"meaning\" of words\n",
    "        window=15, # this is the number of neighboring words to consider when assigning \"meaning\" to a word\n",
    "        min_count=minValue, # minimum number of occurrences\n",
    "        alpha = 0.005,\n",
    "        iter =  epochs) # this is how fast the model adapts its representation of the \"meaning\" of a word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_bestpara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dissatisfaction</td>\n",
       "      <td>0.559937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insecurity</td>\n",
       "      <td>0.502478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attitude</td>\n",
       "      <td>0.489941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>performance</td>\n",
       "      <td>0.483670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affective</td>\n",
       "      <td>0.467869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>satis</td>\n",
       "      <td>0.449520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happiness</td>\n",
       "      <td>0.445725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>attitudinal</td>\n",
       "      <td>0.437997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>depression</td>\n",
       "      <td>0.429678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>manager-rated</td>\n",
       "      <td>0.426777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  similarity\n",
       "0  dissatisfaction    0.559937\n",
       "1       insecurity    0.502478\n",
       "2         attitude    0.489941\n",
       "3      performance    0.483670\n",
       "4        affective    0.467869\n",
       "5            satis    0.449520\n",
       "6        happiness    0.445725\n",
       "7      attitudinal    0.437997\n",
       "8       depression    0.429678\n",
       "9    manager-rated    0.426777"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "pd.DataFrame(model_bestpara.wv.most_similar(positive = ['satisfaction'], topn=10), columns = ['word', 'similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model with 96% percentile \n",
    "model_bestpara.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model1_96_percentile.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model with 95% percentile\n",
    "model_bestpara.save('C:/Thesis/Data/save/Master_Data/Model/latest/word2vec/word2vec_model1.model') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
